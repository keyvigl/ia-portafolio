---
title: "ğŸ§  PrÃ¡ctica 7 â€” De PerceptrÃ³n a Redes Neuronales"
date: 2025-09-18
---

# ğŸ§  PrÃ¡ctica 7 â€” De PerceptrÃ³n a Redes Neuronales
**Unidad TemÃ¡tica 2 â€” Deep Learning Foundations**

---

## ğŸ“˜ Contexto General

En esta prÃ¡ctica se estudiÃ³ la evoluciÃ³n desde el **PerceptrÃ³n clÃ¡sico de una sola capa** hasta una **Red Neuronal Multicapa (MLP)**, entendiendo cÃ³mo la incorporaciÃ³n de capas ocultas, funciones de activaciÃ³n y optimizaciÃ³n no lineal permiten resolver problemas mÃ¡s complejos.

El objetivo fue **experimentar con modelos simples y progresivamente mÃ¡s profundos**, midiendo el efecto en la frontera de decisiÃ³n, la convergencia y la precisiÃ³n.

---

## ğŸ¯ Objetivos de Aprendizaje

1. Analizar el comportamiento del **PerceptrÃ³n simple** como clasificador lineal.  
2. Implementar una **Red Neuronal Multicapa (MLP)** para problemas no lineales.  
3. Observar y comparar las **fronteras de decisiÃ³n** entre ambos modelos.  
4. Evaluar el efecto de la funciÃ³n de activaciÃ³n y el nÃºmero de capas ocultas.  
5. Visualizar el proceso de entrenamiento (curvas de pÃ©rdida y precisiÃ³n).

---

## ğŸ§© Fundamentos TeÃ³ricos

El **PerceptrÃ³n simple** constituye la base de las redes neuronales modernas.  
MatemÃ¡ticamente, su salida se define como:

\[
\hat{y} = f(W \cdot X + b)
\]

donde `f()` es una funciÃ³n de activaciÃ³n tipo â€œpasoâ€ que sÃ³lo permite **fronteras lineales**.

Sin embargo, muchos problemas reales (como los datasets de tipo â€œXORâ€ o â€œMoonsâ€) **no son linealmente separables**.  
AhÃ­ entra el **MLP (Multilayer Perceptron)**, que introduce capas ocultas y activaciones no lineales (`ReLU`, `Sigmoid`, `Tanh`) para **modelar relaciones complejas**.

---

## âš™ï¸ MetodologÃ­a y Dataset

Para comparar ambos modelos se usÃ³ el dataset **Make Moons**, incluido en `scikit-learn`.  
Este dataset genera dos medias lunas entrelazadas, ideales para probar la capacidad de generalizaciÃ³n de redes neuronales.

**Pipeline aplicado:**

1. GeneraciÃ³n del dataset: 1000 muestras (`make_moons` con ruido = 0.2).  
2. DivisiÃ³n en entrenamiento (80%) y prueba (20%).  
3. EstandarizaciÃ³n con `StandardScaler`.  
4. Entrenamiento:
   - Modelo 1: `Perceptron()`  
   - Modelo 2: `MLPClassifier(hidden_layer_sizes=(10,), activation='relu', solver='adam')`
5. EvaluaciÃ³n mediante `accuracy_score`, visualizaciÃ³n de fronteras y curvas de pÃ©rdida.

---

## ğŸ“Š ExploraciÃ³n del Dataset

El conjunto presenta **dos clases bien definidas**, pero con una frontera no lineal.  
Esto permite comprobar cÃ³mo el perceptrÃ³n fracasa al tratar de separarlas linealmente,  
mientras que el MLP logra adaptarse al contorno.


> Se observa el entrelazado caracterÃ­stico que desafÃ­a a los modelos lineales.

---

## ğŸ§  Modelo 1 â€” PerceptrÃ³n Simple

El perceptrÃ³n fue entrenado con **descenso de gradiente estocÃ¡stico** (`max_iter=1000`)  
para ajustar los pesos y minimizar los errores de clasificaciÃ³n.

ğŸ“ˆ **EcuaciÃ³n de actualizaciÃ³n de pesos:**

\[
w_{t+1} = w_t + \eta (y_i - \hat{y_i}) x_i
\]

donde `Î·` es la tasa de aprendizaje.

---


En esta primera parte, se implementaron perceptrones para simular comportamientos de **operadores lÃ³gicos bÃ¡sicos**: AND, OR, NOT y XOR.  
Cada uno fue evaluado segÃºn su capacidad de aprendizaje y su frontera de decisiÃ³n.

---

### ğŸ“Š **Resolvemos AND**
![AND](../assets/pr1.png)

**InterpretaciÃ³n:**
- El perceptrÃ³n logra **ajustar correctamente la lÃ³gica AND**, ya que es **linealmente separable**.  
- La frontera de decisiÃ³n (una lÃ­nea recta) separa con precisiÃ³n las combinaciones vÃ¡lidas (`1 âˆ§ 1 = 1`) del resto (`0`).

> ğŸ”¹ Resultado: el perceptrÃ³n **converge rÃ¡pidamente** sin necesidad de capas adicionales.

---

### ğŸ“Š **Resolvemos OR**
![OR](../assets/pr2.png)

**InterpretaciÃ³n:**
- La lÃ³gica OR tambiÃ©n es **linealmente separable**, por lo tanto el perceptrÃ³n la resuelve sin dificultad.  
- Basta con que uno de los valores de entrada sea 1 para que la salida sea 1.

> ğŸ”¹ Resultado: aprendizaje correcto, **baja tasa de error y convergencia rÃ¡pida**.

---

### ğŸ“Š **Resolvemos NOT**
![NOT](../assets/pr3.png)

**InterpretaciÃ³n:**
- La operaciÃ³n NOT invierte la entrada: `1 â†’ 0`, `0 â†’ 1`.  
- En este caso, el modelo se reduce a un **Ãºnico nodo con un peso negativo**, sin necesidad de umbral complejo.  
- Es el ejemplo mÃ¡s simple y demuestra el principio de la **funciÃ³n de activaciÃ³n** (aquÃ­, tipo escalÃ³n).

> ğŸ”¹ Resultado: la red aprende perfectamente la **inversiÃ³n lÃ³gica**.

---

### ğŸ“Š **Problema XOR**
![XOR](../assets/pr4.png)

**InterpretaciÃ³n:**
- El perceptrÃ³n **falla al intentar resolver XOR**, ya que este problema **no es linealmente separable**.  
- No existe una lÃ­nea recta que divida correctamente las clases.  
- Los puntos `(0,1)` y `(1,0)` comparten la misma etiqueta positiva, pero estÃ¡n en lados opuestos del plano.

> âš ï¸ Resultado: el perceptrÃ³n **no converge** â†’ se requiere **no linealidad** y **capas ocultas**.  
> Esto motiva el desarrollo del **MLP (Multilayer Perceptron)**.

---
**AnÃ¡lisis:**
- La frontera es *lineal y rÃ­gida*.  
- No logra seguir el contorno curvo del dataset, clasificando errÃ³neamente zonas amplias.  
- Presenta oscilaciones en el entrenamiento debido a la naturaleza no separable de los datos.

---

## ğŸ§¬ Modelo 2 â€” Red Neuronal Multicapa (MLP)

El modelo MLP fue entrenado con:
- 1 capa oculta de 10 neuronas  
- ActivaciÃ³n: `ReLU`  
- Optimizador: `Adam`  
- Ã‰pocas: 500  

ğŸ“‰ **Arquitectura del modelo:**

| Capa | Tipo | Neuronas | ActivaciÃ³n |
|------|------|-----------|------------|
| Input | Dense | 2 | â€” |
| Oculta | Dense | 10 | ReLU |
| Output | Dense | 1 | Sigmoid |

---

### ğŸ”¹ Entrenamiento y Convergencia

El MLP muestra una **curva de pÃ©rdida decreciente y estable**,
evidenciando un proceso de aprendizaje adecuado.

![Curva de pÃ©rdida del MLP](../assets/pr5.png)
![Curva de pÃ©rdida del MLP](../assets/pr6.png)
- La pÃ©rdida desciende suavemente, indicando convergencia.  
- A diferencia del perceptrÃ³n, no se observan fluctuaciones grandes.  
- El modelo logra generalizar bien sin sobreajustarse.

---

### ğŸ”¹ Frontera de DecisiÃ³n del MLP

![Frontera de decisiÃ³n del MLP](../assets/pr7.png)

**AnÃ¡lisis visual:**
- La frontera se adapta perfectamente a la forma curva del dataset.  
- Clasifica correctamente casi todos los puntos.  
- Se observa cÃ³mo el modelo â€œdoblaâ€ el espacio lineal a travÃ©s de las capas ocultas.

---

### ğŸ”¹ MÃ©tricas de desempeÃ±o

| MÃ©trica | Valor |
|----------|--------|
| Accuracy (Train) | 0.98 |
| Accuracy (Test) | 0.97 |
| Ã‰pocas efectivas | 421 |

**ConclusiÃ³n parcial:**  
El MLP no solo mejora la exactitud, sino que **aprende patrones complejos** imposibles de capturar por el perceptrÃ³n lineal.

---

## ğŸ” Comparativa Global

| Aspecto | PerceptrÃ³n | Red Neuronal (MLP) |
|----------|-------------|---------------------|
| Capas ocultas | 0 | 1 |
| Tipo de frontera | Lineal | No lineal |
| FunciÃ³n de activaciÃ³n | Paso | ReLU |
| DesempeÃ±o en test | 74% | 97% |
| Convergencia | RÃ¡pida pero limitada | Lenta y estable |
| Interpretabilidad | Alta | Media |
| Capacidad de generalizaciÃ³n | Baja | Alta |

ğŸ“ˆ **VisualizaciÃ³n comparativa de fronteras**
![ComparaciÃ³n de fronteras](../assets/pr8.png)

> En la comparaciÃ³n visual, se aprecia cÃ³mo la red neuronal logra una separaciÃ³n fluida y adaptativa,  
> mientras que el perceptrÃ³n falla en capturar la curvatura de los datos.

---

## ğŸ§  ReflexiÃ³n Final

Esta prÃ¡ctica representa el **primer contacto con la arquitectura neuronal moderna**.  
MÃ¡s allÃ¡ del cÃ³digo, el aprendizaje central fue **entender cÃ³mo una red neuronal aprende representaciones jerÃ¡rquicas**  
y por quÃ© eso cambia radicalmente la forma de resolver problemas.

**Conclusiones principales:**
- El **perceptrÃ³n** funciona solo con problemas lineales; su frontera es rÃ­gida.  
- El **MLP** introduce **no linealidad y profundidad**, lo que amplÃ­a enormemente el espacio de soluciones.  
- La visualizaciÃ³n de la frontera de decisiÃ³n y la curva de pÃ©rdida **revela el proceso de aprendizaje real**,  
  mucho mÃ¡s informativo que las mÃ©tricas numÃ©ricas.

> ğŸ§© *â€œLas redes neuronales no solo clasifican: transforman el espacio hasta que el problema se vuelve lineal.â€*

---

## ğŸš€ PrÃ³ximos pasos

- Experimentar con **distintas funciones de activaciÃ³n** (Sigmoid, Tanh, ReLU).  
- Probar arquitecturas mÃ¡s profundas y evaluar **overfitting / underfitting**.  
- Introducir **regularizaciÃ³n** (`Dropout`, `Batch Normalization`).  
- Comparar optimizadores: `SGD`, `Adam`, `RMSProp`.

---

## ğŸ“ Evidencias

- ğŸ“ Notebook original: `Practica7_DePerceptron_a_RedesNeuronales.ipynb`  
- ğŸ“Š ImÃ¡genes y visualizaciones:
  - `distribucion_dataset.png`
  - `frontera_perceptron.png`
  - `frontera_mlp.png`
  - `curva_perdida_mlp.png`
  - `comparacion_fronteras.png`
- ğŸ“ˆ Reporte tÃ©cnico exportado a PDF: `Practica7_Informe.pdf`

---
## ğŸ¤” Preguntas de ReflexiÃ³n â€” Respuestas

**Â¿Por quÃ© AND, OR y NOT funcionaron pero XOR no?**  
Porque AND/OR/NOT son linealmente separables (una sola recta/umbral basta), mientras que XOR no: sus clases estÃ¡n en esquinas alternadas del plano y ninguna recta puede separarlas perfectamente. Para XOR necesitas mÃºltiples fronteras (capas) â†’ no linealidad.

---

**Â¿Diferencia clave entre los pesos de AND vs OR?**  
El **umbral**.  
- AND exige mÃ¡s evidencia â†’ pesos similares pero bias mÃ¡s negativo.  
- OR es mÃ¡s permisivo â†’ bias menos negativo.

---

**Â¿Problemas reales tipo XOR?**  
Cualquier regla â€œesto O aquello, pero no ambosâ€:  
- Alarmas que se disparan si solo un sensor detecta evento.  
- Accesos con condiciones mutuamente excluyentes.  
- DiagnÃ³stico donde dos hallazgos juntos anulan la probabilidad.

---

**Â¿Por quÃ© sklearn MLP resuelve XOR y un perceptrÃ³n no?**  
Porque el MLP (con capa oculta + activaciÃ³n no lineal) combina varias fronteras â†’ forma regiones curvas/compuestas.  
El perceptrÃ³n simple solo dibuja una recta.

---

**Â¿Diferencia principal entre TensorFlow/Keras y sklearn MLP?**  
- **Keras/TensorFlow:** framework profundo, control total, GPUs, callbacks.  
- **sklearn MLP:** simple y rÃ¡pido, pero con menos flexibilidad.

---

**Â¿Por quÃ© TensorFlow usa epochs y batch_size y sklearn MLP â€œnoâ€?**  
En Keras defines explÃ­citamente los bucles (`epochs`, `batches`).  
En sklearn, `.fit()` lo gestiona internamente de forma automÃ¡tica.

---

**Â¿CuÃ¡ndo usar sigmoid vs ReLU?**  
- **Sigmoid:** para salidas binarias (probabilidad).  
- **ReLU:** en capas ocultas (evita saturaciÃ³n y acelera convergencia).

---

**Â¿Ventaja de PyTorch Lightning sobre TensorFlow puro?**  
Simplifica el cÃ³digo, mantiene flexibilidad y estructura clara para investigaciÃ³n y escalamiento.

---

**Â¿Por quÃ© Lightning separa training_step y test_step?**  
Porque en `training_step` se calcula pÃ©rdida y backprop, mientras en `test_step` solo se evalÃºa sin actualizar pesos.  
Esto asegura **buenas prÃ¡cticas y reproducibilidad.**

---

**Â¿QuÃ© framework elegirÃ­as para cada escenario?**  
- **Prototipo rÃ¡pido:** sklearn o Keras Sequential simple.  
- **ProducciÃ³n:** TensorFlow/Keras o PyTorch con TorchServe.  
- **InvestigaciÃ³n:** PyTorch + Lightning.

---

**Â¿Por quÃ© aparece el error â€œmat1 and mat2 shapes cannot be multipliedâ€ en PyTorch?**  
Porque la dimensiÃ³n de entrada del `Linear` no coincide con los features del tensor.  
Si defines `nn.Linear(20, 64)`, tu input debe ser `(batch, 20)`.

---

**Â¿QuÃ© significa deterministic=True en Trainer (Lightning)?**  
Activa la reproducibilidad total del entrenamiento (semillas fijas y sin aleatoriedad).  
Ideal para comparar experimentos.

---

**Â¿Por quÃ© TensorFlow muestra loss y val_loss durante entrenamiento?**  
Para monitorear **overfitting**: si `loss â†“` pero `val_loss â†‘`, el modelo estÃ¡ memorizando â†’ aplicar regularizaciÃ³n o early stopping.

---

**Diferencia entre trainer.test() y trainer.predict() en Lightning**  
- `test()`: evalÃºa con mÃ©tricas y logging.  
- `predict()`: genera predicciones sin calcular mÃ©tricas.

---

**Â¿Por quÃ© sklearn MLP es mÃ¡s fÃ¡cil pero menos flexible?**  
Porque abstrae los detalles de entrenamiento (sin control de Ã©pocas, batches, optimizadores o callbacks).  
Ideal para aprendizaje inicial, pero limitado en escenarios avanzados.

---

ğŸ“„ **Notebook original:** `Practica7_DePerceptron_a_RedesNeuronales.ipynb`  
ğŸ§© **Tipo de prÃ¡ctica:** Experimental â€” Fundamentos de Deep Learning

---