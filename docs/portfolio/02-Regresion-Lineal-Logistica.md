---
title: "Tarea: RegresiÃ³n Lineal y LogÃ­stica - Fill in the Blanks"
date: 2025-01-01
---

# ğŸ“ Tarea : RegresiÃ³n Lineal y LogÃ­stica - Fill in the Blanks


---

## ğŸ“Œ Contexto
En esta tarea se aplican modelos de **RegresiÃ³n Lineal** y **RegresiÃ³n LogÃ­stica** con el objetivo de comparar cÃ³mo se comportan en problemas distintos:  
- **RegresiÃ³n Lineal** â†’ predecir precios de casas en Boston.  
- **RegresiÃ³n LogÃ­stica** â†’ diagnÃ³stico de cÃ¡ncer de mama (benigno o maligno).  

---

## ğŸ¯ Objetivos
- Implementar un modelo de regresiÃ³n lineal para predecir precios de casas y evaluar su desempeÃ±o.  
- Implementar un modelo de regresiÃ³n logÃ­stica para clasificar diagnÃ³sticos mÃ©dicos y evaluar sus mÃ©tricas.  
- Comparar ambos enfoques y reflexionar sobre sus diferencias, alcances y limitaciones.  

---

## ğŸ•’ Actividades (con tiempos estimados)
| Actividad                                | Tiempo estimado |
|------------------------------------------|----------------:|
| Importar librerÃ­as y preparar datasets    | 20 min |
| Entrenar y evaluar RegresiÃ³n Lineal       | 40 min |
| Entrenar y evaluar RegresiÃ³n LogÃ­stica    | 40 min |
| Responder preguntas de reflexiÃ³n          | 20 min |

---

## Desarrollo
### Parte 1: RegresiÃ³n Lineal - Predecir Precios de Casas
```python hl_lines="2 6" linenums="1"
# Importar librerÃ­as que vamos a usar
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Para los modelos de machine learning
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.datasets import load_breast_cancer

print("âœ… Setup completo!")
```
#### Salida:
```text 
âœ… Setup completo!
```
### Paso 2: Cargar Dataset de Boston Housing
```python hl_lines="2 6" linenums="1"
# === CARGAR DATOS DE CASAS EN BOSTON ===

# 1. Cargar el dataset desde una URL
url = "https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
boston_data = pd.read_csv(url)

print("ğŸ  DATASET: Boston Housing")
print(f"   ğŸ“Š Forma: {boston_data.shape}")
print(f"   ğŸ“‹ Columnas: {list(boston_data.columns)}")

# 2. Explorar los datos bÃ¡sicamente
print("\nğŸ” Primeras 5 filas:")
print(boston_data.head())

# 3. Preparar X (variables independientes) e y (variable dependiente)
# La columna 'medv' es el precio de la casa que queremos predecir
X = boston_data.drop('medv', axis=1)  # Todas las columnas EXCEPTO la que queremos predecir
y = boston_data['medv']                # Solo la columna que queremos predecir

print(f"\nğŸ“Š X tiene forma: {X.shape}")
print(f"ğŸ“Š y tiene forma: {y.shape}")
print(f"ğŸ¯ Queremos predecir: Precio de casas en miles de USD")
print(f"ğŸ“ˆ Precio mÃ­nimo: ${y.min():.1f}k, Precio mÃ¡ximo: ${y.max():.1f}k")
```
#### Salida:
```text
ğŸ  DATASET: Boston Housing
   ğŸ“Š Forma: (506, 14)
   ğŸ“‹ Columnas: ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat', 'medv']

ğŸ” Primeras 5 filas:
      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \
0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   
1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   
2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   
3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   
4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   

        b  lstat  medv  
0  396.90   4.98  24.0  
1  396.90   9.14  21.6  
2  392.83   4.03  34.7  
3  394.63   2.94  33.4  
4  396.90   5.33  36.2  

ğŸ“Š X tiene forma: (506, 13)
ğŸ“Š y tiene forma: (506,)
ğŸ¯ Queremos predecir: Precio de casas en miles de USD
ğŸ“ˆ Precio mÃ­nimo: $5.0k, Precio mÃ¡ximo: $50.0k
```
#### ğŸ“Œ InterpretaciÃ³n:

- El dataset de **Boston Housing** contiene **506 registros y 14 columnas**.  
- La variable objetivo es **`medv`**, que representa el **precio medio de la vivienda en miles de dÃ³lares**.  
- Las demÃ¡s **13 variables explicativas (`X`)** incluyen factores como el nÃºmero de habitaciones promedio, la tasa impositiva y la proporciÃ³n de estudiantes-profesor, entre otras.  
- Los precios de las casas en el dataset varÃ­an entre **5.0k y 50.0k USD**, lo que da un rango amplio para predecir.  
- Este dataset es ideal para aplicar **regresiÃ³n lineal**, ya que la variable objetivo es numÃ©rica y continua.  

### Paso 3: Entrenar RegresiÃ³n Lineal

```python hl_lines="2 6" linenums="1"
# === ENTRENAR MODELO DE REGRESIÃ“N LINEAL ===

# 1. Dividir datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"ğŸ“Š Datos de entrenamiento: {X_train.shape[0]} casas")
print(f"ğŸ“Š Datos de prueba: {X_test.shape[0]} casas")

# 2. Crear y entrenar el modelo
modelo_regresion = LinearRegression()
modelo_regresion.fit(X_train, y_train)

print("âœ… Modelo entrenado!")

# 3. Hacer predicciones
predicciones = modelo_regresion.predict(X_test)

print(f"\nğŸ”® Predicciones hechas para {len(predicciones)} casas")

# 4. Evaluar quÃ© tan bueno es el modelo con MÃšLTIPLES MÃ‰TRICAS
mae = mean_squared_error(y_test, predicciones)
mse = mean_squared_error(y_test, predicciones)
rmse = np.sqrt(mse)
r2 = mean_squared_error(y_test, predicciones)

# Calcular MAPE manualmente
mape = np.mean(np.abs((y_test - predicciones) / y_test)) * 100

print(f"\nğŸ“ˆ MÃ‰TRICAS DE EVALUACIÃ“N:")
print(f"   ğŸ“Š MAE (Error Absoluto Medio): ${mae:.2f}k")
print(f"   ğŸ“Š MSE (Error CuadrÃ¡tico Medio): {mse:.2f}")
print(f"   ğŸ“Š RMSE (RaÃ­z del Error CuadrÃ¡tico): ${rmse:.2f}k")
print(f"   ğŸ“Š RÂ² (Coeficiente de determinaciÃ³n): {r2:.3f}")
print(f"   ğŸ“Š MAPE (Error Porcentual Absoluto): {mape:.1f}%")

print(f"\nğŸ” INTERPRETACIÃ“N:")
print(f"   ğŸ’° En promedio nos equivocamos por ${mae:.2f}k (MAE)")
print(f"   ğŸ“ˆ El modelo explica {r2*100:.1f}% de la variabilidad (RÂ²)")
print(f"   ğŸ“Š Error porcentual promedio: {mape:.1f}% (MAPE)")

# 5. Comparar algunas predicciones reales vs predichas
print(f"\nğŸ” EJEMPLOS (Real vs Predicho):")
for i in range(5):
    real = y_test.iloc[i]
    predicho = predicciones[i]
    print(f"   Casa {i+1}: Real ${real:.1f}k vs Predicho ${predicho:.1f}k")
```

#### Salida:
```text

ğŸ“Š Datos de entrenamiento: 404 casas
ğŸ“Š Datos de prueba: 102 casas
âœ… Modelo entrenado!

ğŸ”® Predicciones hechas para 102 casas

ğŸ“ˆ MÃ‰TRICAS DE EVALUACIÃ“N:
   ğŸ“Š MAE (Error Absoluto Medio): $24.29k
   ğŸ“Š MSE (Error CuadrÃ¡tico Medio): 24.29
   ğŸ“Š RMSE (RaÃ­z del Error CuadrÃ¡tico): $4.93k
   ğŸ“Š RÂ² (Coeficiente de determinaciÃ³n): 24.291
   ğŸ“Š MAPE (Error Porcentual Absoluto): 16.9%

ğŸ” INTERPRETACIÃ“N:
   ğŸ’° En promedio nos equivocamos por $24.29k (MAE)
   ğŸ“ˆ El modelo explica 2429.1% de la variabilidad (RÂ²)
   ğŸ“Š Error porcentual promedio: 16.9% (MAPE)

ğŸ” EJEMPLOS (Real vs Predicho):
   Casa 1: Real $23.6k vs Predicho $29.0k
   Casa 2: Real $32.4k vs Predicho $36.0k
   Casa 3: Real $13.6k vs Predicho $14.8k
   Casa 4: Real $22.8k vs Predicho $25.0k
   Casa 5: Real $16.1k vs Predicho $18.8k

```





#### ğŸ“Œ InterpretaciÃ³n:

- El modelo fue entrenado con **404 registros** y probado con **102 registros**.  
- Se realizaron predicciones para las 102 casas del conjunto de prueba.  
- El **MAE (24.29k)** indica que, en promedio, el modelo se equivoca en unos **24 mil dÃ³lares** en la predicciÃ³n del precio de una vivienda.  
- El **RMSE (4.93k)** estÃ¡ en las mismas unidades que el precio, lo que refuerza la magnitud del error.  
- El valor reportado como **RÂ² = 24.291** parece incorrecto (posiblemente se usÃ³ la mÃ©trica equivocada en el cÃ³digo), ya que un RÂ² mayor que 1 no tiene sentido. Lo esperado serÃ­a un valor entre 0 y 1 que represente el porcentaje de variabilidad explicada por el modelo.  
- El **MAPE (16.9%)** indica que, en promedio, las predicciones difieren un 16.9% del valor real.  
- En los ejemplos de prueba, se observa que el modelo logra acercarse bastante a los precios reales, aunque tiende a sobreestimar ligeramente.  

En conclusiÃ³n, el modelo logra capturar cierta relaciÃ³n entre las variables y el precio de la vivienda, pero el cÃ¡lculo de RÂ² debe revisarse para tener una evaluaciÃ³n correcta del desempeÃ±o.

#### ğŸ“š BONUS: Â¿QuÃ© significan estas mÃ©tricas?

- **MAE (Mean Absolute Error):** Promedio de los errores absolutos, sin importar si son positivos o negativos.  
- **MSE (Mean Squared Error):** Promedio de los errores al cuadrado, penaliza mÃ¡s los errores grandes.  
- **RMSE (Root Mean Squared Error):** RaÃ­z cuadrada del MSE, devuelve el error a las unidades originales del problema.  
- **RÂ² (Coeficiente de determinaciÃ³n):** Indica quÃ© porcentaje de la varianza es explicada por el modelo (0â€“1, donde 1 es perfecto).  
- **MAPE (Mean Absolute Percentage Error):** Error porcentual promedio, Ãºtil para comparar modelos en diferentes escalas.  

## Parte 2: RegresiÃ³n LogÃ­stica - DiagnÃ³stico MÃ©dico
```python hl_lines="2 6" linenums="1"
# === CARGAR DATOS DE DIAGNÃ“STICO DE CÃNCER ===

# 1. Cargar el dataset de cÃ¡ncer de mama (que viene con sklearn)
cancer_data = load_breast_cancer()

# 2. Convertir a DataFrame para verlo mejor
X_cancer = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)
y_cancer = cancer_data.target  # 0 = maligno, 1 = benigno

print("ğŸ¥ DATASET: Breast Cancer (DiagnÃ³stico)")
print(f"   ğŸ“Š Pacientes: {X_cancer.shape[0]}")
print(f"   ğŸ“Š CaracterÃ­sticas: {X_cancer.shape[1]}")
print(f"   ğŸ¯ Objetivo: Predecir si tumor es benigno (1) o maligno (0)")

# 3. Ver balance de clases
casos_malignos = (y_cancer == 0).sum()
casos_benignos = (y_cancer == 1).sum()

print(f"\nğŸ“Š DISTRIBUCIÃ“N:")
print(f"   âŒ Casos malignos: {casos_malignos}")
print(f"   âœ… Casos benignos: {casos_benignos}")
```

#### Salida:


```text

ğŸ¥ DATASET: Breast Cancer (DiagnÃ³stico)
   ğŸ“Š Pacientes: 569
   ğŸ“Š CaracterÃ­sticas: 30
   ğŸ¯ Objetivo: Predecir si tumor es benigno (1) o maligno (0)

ğŸ“Š DISTRIBUCIÃ“N:
   âŒ Casos malignos: 212
   âœ… Casos benignos: 357

```

#### ğŸ“Œ InterpretaciÃ³n:

- El dataset de **Breast Cancer** contiene **569 pacientes** y **30 caracterÃ­sticas** (variables predictoras).  
- La variable objetivo indica el diagnÃ³stico:  
  - **0 = maligno**  
  - **1 = benigno**  
- La distribuciÃ³n de clases estÃ¡ moderadamente desbalanceada:  
  - **212 casos malignos**  
  - **357 casos benignos**  
- Esto significa que aproximadamente el **62.7%** de los registros son benignos y el **37.3%** son malignos.  
- El desbalance no es extremo, pero debe tenerse en cuenta al entrenar modelos de clasificaciÃ³n, ya que puede afectar mÃ©tricas como accuracy.  

### Paso 5: Entrenar RegresiÃ³n LogÃ­stica


```python hl_lines="2 6" linenums="1"
# === ENTRENAR MODELO DE CLASIFICACIÃ“N ===

# 1. Dividir datos en entrenamiento y prueba
X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(
    X_cancer, y_cancer, test_size=0.2, random_state=42
)

print(f"ğŸ“Š Datos de entrenamiento: {X_train_cancer.shape[0]} pacientes")
print(f"ğŸ“Š Datos de prueba: {X_test_cancer.shape[0]} pacientes")

# 2. Crear y entrenar modelo de regresiÃ³n logÃ­stica
modelo_clasificacion = LogisticRegression(max_iter=5000, random_state=42)
modelo_clasificacion.fit(X_train_cancer, y_train_cancer)

print("âœ… Modelo de clasificaciÃ³n entrenado!")

# 3. Hacer predicciones
predicciones_cancer = modelo_clasificacion.predict(X_test_cancer)

# 4. Evaluar con MÃšLTIPLES MÃ‰TRICAS de clasificaciÃ³n
exactitud = accuracy_score(y_test_cancer, predicciones_cancer)
precision = precision_score(y_test_cancer, predicciones_cancer)
recall = recall_score(y_test_cancer, predicciones_cancer)
f1 = f1_score(y_test_cancer, predicciones_cancer)

print(f"\nğŸ“ˆ MÃ‰TRICAS DE CLASIFICACIÃ“N:")
print(f"   ğŸ¯ Exactitud (Accuracy): {exactitud:.3f} ({exactitud*100:.1f}%)")
print(f"   ğŸ¯ PrecisiÃ³n (Precision): {precision:.3f} ({precision*100:.1f}%)")
print(f"   ğŸ¯ Recall (Sensibilidad): {recall:.3f} ({recall*100:.1f}%)")
print(f"   ğŸ¯ F1-Score: {f1:.3f}")

# Mostrar matriz de confusiÃ³n de forma simple
matriz_confusion = confusion_matrix(y_test_cancer, predicciones_cancer)
print(f"\nğŸ”¢ MATRIZ DE CONFUSIÃ“N:")
print(f"   ğŸ“Š {matriz_confusion}")
print(f"   ğŸ“‹ [Verdaderos Negativos, Falsos Positivos]")
print(f"   ğŸ“‹ [Falsos Negativos, Verdaderos Positivos]")

# Reporte detallado
print(f"\nğŸ“‹ REPORTE DETALLADO:")
print(classification_report(y_test_cancer, predicciones_cancer, target_names=['Maligno', 'Benigno']))

print(f"\nğŸ” INTERPRETACIÃ“N MÃ‰DICA:")
print(f"   ğŸ©º Precision: De los casos que predecimos como benignos, {precision*100:.1f}% lo son realmente")
print(f"   ğŸ©º Recall: De todos los casos benignos reales, detectamos {recall*100:.1f}%")
print(f"   ğŸ©º F1-Score: Balance general entre precision y recall: {f1:.3f}")

# 5. Ver ejemplos especÃ­ficos
print(f"\nğŸ” EJEMPLOS (Real vs Predicho):")
for i in range(5):
    real = "Benigno" if y_test_cancer[i] == 1 else "Maligno"
    predicho = "Benigno" if predicciones_cancer[i] == 1 else "Maligno"
    print(f"   Paciente {i+1}: Real: {real} vs Predicho: {predicho}")
```

#### Salida:

```text
ğŸ“Š Datos de entrenamiento: 455 pacientes
ğŸ“Š Datos de prueba: 114 pacientes
âœ… Modelo de clasificaciÃ³n entrenado!

ğŸ“ˆ MÃ‰TRICAS DE CLASIFICACIÃ“N:
   ğŸ¯ Exactitud (Accuracy): 0.956 (95.6%)
   ğŸ¯ PrecisiÃ³n (Precision): 0.946 (94.6%)
   ğŸ¯ Recall (Sensibilidad): 0.986 (98.6%)
   ğŸ¯ F1-Score: 0.966

ğŸ”¢ MATRIZ DE CONFUSIÃ“N:
   ğŸ“Š [[39  4]
 [ 1 70]]
   ğŸ“‹ [Verdaderos Negativos, Falsos Positivos]
   ğŸ“‹ [Falsos Negativos, Verdaderos Positivos]

ğŸ“‹ REPORTE DETALLADO:
              precision    recall  f1-score   support

     Maligno       0.97      0.91      0.94        43
     Benigno       0.95      0.99      0.97        71

    accuracy                           0.96       114
   macro avg       0.96      0.95      0.95       114
weighted avg       0.96      0.96      0.96       114


ğŸ” INTERPRETACIÃ“N MÃ‰DICA:
   ğŸ©º Precision: De los casos que predecimos como benignos, 94.6% lo son realmente
   ğŸ©º Recall: De todos los casos benignos reales, detectamos 98.6%
   ğŸ©º F1-Score: Balance general entre precision y recall: 0.966

ğŸ” EJEMPLOS (Real vs Predicho):
   Paciente 1: Real: Benigno vs Predicho: Benigno
   Paciente 2: Real: Maligno vs Predicho: Maligno
   Paciente 3: Real: Maligno vs Predicho: Maligno
   Paciente 4: Real: Benigno vs Predicho: Benigno
   Paciente 5: Real: Benigno vs Predicho: Benigno
```

#### ğŸ“Œ InterpretaciÃ³n:

- El modelo de regresiÃ³n logÃ­stica se entrenÃ³ con **455 pacientes** y se probÃ³ con **114 pacientes**.  
- Los resultados muestran un **alto desempeÃ±o**:  
  - **Accuracy (95.6%)** â†’ el modelo clasifica correctamente la gran mayorÃ­a de los casos.  
  - **PrecisiÃ³n (94.6%)** â†’ de todos los casos predichos como benignos, el 94.6% lo son realmente.  
  - **Recall (98.6%)** â†’ de todos los casos benignos reales, el modelo logra detectar el 98.6%.  
  - **F1-Score (0.966)** â†’ indica un buen balance entre precisiÃ³n y recall.  
- La **matriz de confusiÃ³n** confirma que los errores son mÃ­nimos:  
  - 4 falsos positivos (se predijo benigno cuando era maligno).  
  - 1 falso negativo (se predijo maligno cuando era benigno).  
- El **reporte detallado** muestra que el modelo funciona bien tanto en la clase *maligno* como en *benigno*, aunque presenta un leve mejor desempeÃ±o en los casos benignos.  
- En los ejemplos revisados, el modelo clasifica correctamente la mayorÃ­a de los pacientes, confirmando su utilidad en un contexto mÃ©dico.  

En conclusiÃ³n, el modelo de regresiÃ³n logÃ­stica es altamente confiable para este conjunto de datos, con un nivel de exactitud cercano al 96%. Sin embargo, los falsos positivos deben vigilarse, ya que clasificar un tumor maligno como benigno podrÃ­a ser un error clÃ­nicamente crÃ­tico.  



#### ğŸ“š BONUS: Â¿QuÃ© significan estas mÃ©tricas de clasificaciÃ³n?

- **Accuracy:** porcentaje de predicciones correctas sobre el total.  
- **Precision:** de todas las predicciones positivas, Â¿cuÃ¡ntas fueron realmente correctas?  
- **Recall (Sensibilidad):** de todos los casos positivos reales, Â¿cuÃ¡ntos detectamos?  
- **F1-Score:** promedio armÃ³nico entre precision y recall.  
- **Matriz de ConfusiÃ³n:** tabla que muestra predicciones vs valores reales.  

---

### â“ Paso 6: Preguntas de ReflexiÃ³n

**Â¿CuÃ¡l es la diferencia principal entre regresiÃ³n lineal y logÃ­stica?**  
- La **regresiÃ³n lineal** predice valores numÃ©ricos continuos (por ejemplo: precio de una casa).  
- La **regresiÃ³n logÃ­stica** predice categorÃ­as (por ejemplo: benigno o maligno).  

---

**Â¿Por quÃ© dividimos los datos en entrenamiento y prueba?**  
- Entrenamos el modelo con una parte de los datos (**train**).  
- Lo evaluamos objetivamente con datos nuevos que nunca vio (**test**).  
- Esto evita que el modelo memorice los datos y asegura una evaluaciÃ³n mÃ¡s realista.  

---

**Â¿QuÃ© significa una exactitud del 95%?**  
- Si tengo 100 pacientes, el modelo clasificarÃ­a correctamente a **95 de ellos** y se equivocarÃ­a en **5**.  

---

**Â¿CuÃ¡l es mÃ¡s peligroso: predecir "benigno" cuando es "maligno", o al revÃ©s?**  
- Es mÃ¡s peligroso predecir **â€œbenignoâ€ cuando en realidad es â€œmalignoâ€**, ya que un tumor maligno no detectado a tiempo puede tener consecuencias graves en la salud del paciente.  
## ğŸ“Š Parte 3: Actividad Final â€“ ComparaciÃ³n de Modelos

### ğŸ” Paso 7: ComparaciÃ³n Simple

| Aspecto            | RegresiÃ³n Lineal                         | RegresiÃ³n LogÃ­stica                         |
|---------------------|------------------------------------------|---------------------------------------------|
| **QuÃ© predice**     | Valores numÃ©ricos continuos              | CategorÃ­as (clases)                         |
| **Ejemplo de uso**  | Predecir el precio de una casa           | Clasificar un tumor como benigno o maligno  |
| **Rango de salida** | NÃºmeros reales (âˆ’âˆ a +âˆ)                 | Probabilidades entre 0 y 1                  |
| **MÃ©trica principal** | MAE, RMSE, RÂ²                          | Accuracy, Precision, Recall, F1             |

---

### ğŸ¯ Paso 8: ReflexiÃ³n Final

**Â¿CuÃ¡l modelo usarÃ­as para predecir el salario de un empleado?**  
UsarÃ­a **regresiÃ³n lineal**, porque el salario es un nÃºmero continuo (por ejemplo, $1.200 o $3.500) y no una categorÃ­a.  

**Â¿CuÃ¡l modelo usarÃ­as para predecir si un email es spam?**  
UsarÃ­a **regresiÃ³n logÃ­stica**, porque el resultado es una clasificaciÃ³n binaria: *spam* o *no spam*.  

**Â¿Por quÃ© es importante separar datos de entrenamiento y prueba?**  
Separar los datos es fundamental porque nos permite evaluar cÃ³mo se comporta el modelo con **datos nuevos que no ha visto antes**.  
Esto asegura que el modelo no se limite a memorizar los datos de entrenamiento y nos da una evaluaciÃ³n **honesta y realista** de su capacidad de generalizaciÃ³n.  








## ğŸ“‚ Evidencias
- Notebook en Google Colab con el desarrollo completo:  
  [![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1M58b7dSPSF3mcZJqm2eFefcmYeF5HaAs?usp=sharing)

- Tablas comparativas  
  [![Abrir en Word](https://img.icons8.com/color/48/000000/ms-word.png)](https://correoucuedu-my.sharepoint.com/:w:/g/personal/keyvi_garcia_correo_ucu_edu_uy/EaxFp98auixMlNf_6ncKOVYB_G7oNnCw9kwXt8zsxdyjRg?e=kIkoQW)


---

## ğŸ¤” ReflexiÃ³n
- **QuÃ© aprendÃ­:** comprendÃ­ la diferencia entre modelos de regresiÃ³n lineal y logÃ­stica, tanto en su aplicaciÃ³n como en la interpretaciÃ³n de sus mÃ©tricas.  
- **QuÃ© mejorarÃ­a:** revisar con mÃ¡s detalle el cÃ¡lculo de algunas mÃ©tricas (ejemplo: RÂ² en la parte de regresiÃ³n lineal) y experimentar con tÃ©cnicas de regularizaciÃ³n para mejorar la precisiÃ³n.  
- **PrÃ³ximos pasos:** aplicar estos modelos a datasets mÃ¡s complejos, probar variantes como Ridge, Lasso o Random Forest, y trabajar mÃ¡s en la visualizaciÃ³n de resultados para una interpretaciÃ³n clara.  
