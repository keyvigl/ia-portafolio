---
title: "Pr√°ctica 9x ‚Äî Transfer Learning Avanzado: Arquitecturas, Datasets y Fine-Tuning Experimental"
date: 2025-01-15
---

# üß† Pr√°ctica 9x ‚Äî Transfer Learning Avanzado  
**Unidad 3 ‚Äî Computer Vision**

En esta pr√°ctica extendida exploramos el poder del **Transfer Learning** aplicado a distintos **datasets de visi√≥n por computadora**, comparando arquitecturas modernas de redes convolucionales y estrategias de *fine-tuning*.  
Este trabajo complementa la *Pr√°ctica 9 ‚Äî CNNs y Transfer Learning* y busca ir m√°s all√° del ejemplo base, introduciendo experimentos y reflexiones m√°s profundas.

---

## üéØ Objetivos

- Analizar **diferentes arquitecturas CNN pre-entrenadas** (VGG19, ResNet50, EfficientNetB0, MobileNetV3Large).  
- Evaluar el rendimiento en **diferentes dominios visuales** (animales, alimentos, salud vegetal).  
- Implementar **fine-tuning**, **regularizaci√≥n** y **data augmentation**.  
- Reflexionar sobre los resultados y su impacto en proyectos reales.

---

## üì¶ Datasets utilizados

Se seleccionaron tres datasets p√∫blicos y gratuitos desde **Kaggle** y TensorFlow Datasets.

| Dataset | Dominio | N¬∫ Clases | Enlace |
|----------|----------|------------|--------|
| üêæ **Cats vs Dogs** | Clasificaci√≥n binaria | 2 | [Kaggle - Dogs vs Cats](https://www.kaggle.com/datasets/salader/dogs-vs-cats) |
| üåø **PlantVillage** | Diagn√≥stico de enfermedades en hojas | 38 | [Kaggle - PlantVillage Dataset](https://www.kaggle.com/datasets/abdallahalidev/plantvillage-dataset) |
| üçî **Food-101** | Clasificaci√≥n de platos de comida | 101 | [Kaggle - Food-101](https://www.kaggle.com/datasets/kmader/food41) |


---

## üß± Arquitecturas comparadas

Modelos pre-entrenados en **ImageNet**, importados desde `tensorflow.keras.applications`:

```python
models_to_test = [
    'ResNet50', 'VGG19', 'EfficientNetB0', 'MobileNetV3Large'
]
```

Cada modelo se prob√≥ bajo dos configuraciones:

| Configuraci√≥n | Descripci√≥n |
|----------------|-------------|
| üîí **Base congelada** | Solo se entrena el *head* denso final (transfer learning b√°sico). |
| üîì **Fine-tuning parcial** | Se liberan las √∫ltimas capas convolucionales para ajuste fino. |

---

## ‚öôÔ∏è Preparaci√≥n del pipeline

### Preprocesamiento y augmentaci√≥n

```python
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)
```

**Interpretaci√≥n:**  
- Mantiene consistencia de datos con *rescale*.  
- A√±ade *ruido controlado* (rotaciones, desplazamientos) que mejora generalizaci√≥n.  

üìä *Ejemplo de batch visualizado (Cats vs Dogs)*  
![Ejemplo de batch visualizado (Cats vs Dogs)](../assets/tra01.png)


---

## üß© Entrenamiento de arquitecturas

Cada modelo se entren√≥ por **5 epochs** (baseline) con `Adam(lr=1e-4)` y `binary_crossentropy`.

| Modelo | Dataset | Val Accuracy (‚âà) | Comentario |
|---------|----------|------------------|-------------|
| **VGG19** | Cats vs Dogs | 0.88 | Buen desempe√±o, converge r√°pido. |
| **ResNet50** | Cats vs Dogs | 0.90 | Estable, mejor generalizaci√≥n. |
| **EfficientNetB0** | Cats vs Dogs | 0.94 | Excelente balance entre tama√±o y rendimiento. |
| **MobileNetV3Large** | Cats vs Dogs | 0.92 | Ligero, r√°pido, ideal para inferencia. |

üìà **Gr√°fico comparativo de validaci√≥n**
![Comparaci√≥n de arquitecturas](../assets/tra02.png)

---

## üîß Fine-Tuning

Posteriormente, se habilit√≥ *fine-tuning* parcial (√∫ltimos 20‚Äì30% de capas).

```python
base_model.trainable = True
for layer in base_model.layers[:-50]:
    layer.trainable = False
```

üìä **Curvas de entrenamiento**
![Fine-tuning curvas](../assets/tra03.png)

**Observaciones:**
- La p√©rdida disminuye de forma m√°s suave.
- Las validaciones muestran mejor estabilidad tras liberar capas finales.
- Un *learning rate* bajo (1e-5) fue clave para evitar *catastrophic forgetting*.

---

## üß™ Resultados  

| Dataset | Mejor arquitectura | Accuracy | Tiempo por epoch | Comentario |
|----------|--------------------|-----------|------------------|-------------|
| üêæ Cats vs Dogs | EfficientNetB0 | **0.94** | 35s | Ligero y preciso. |

---

## üîç Evaluaci√≥n visual

### Matriz de confusi√≥n (Cats vs Dogs)
![Confusion Matrix](../assets/tra04.png)

### Ejemplos de predicciones
- ‚úÖ Correctas: claras, buena iluminaci√≥n, rasgos definidos.  
- ‚ùå Incorrectas: im√°genes borrosas, √°ngulos inusuales o mezcla de fondos.

---

## üß† Conclusiones clave

1. **EfficientNetB0** demostr√≥ ser la mejor opci√≥n general por su eficiencia.  
2. **Fine-tuning** mejora la precisi√≥n en datasets m√°s grandes.  
3. **BatchNorm + Dropout** contribuyen fuertemente a la estabilidad.  
4. El **tama√±o del dataset** y la **diversidad de clases** afectan la arquitectura √≥ptima.  

---

## üß≠ Reflexi√≥n personal

> Esta pr√°ctica me permiti√≥ entender c√≥mo los modelos preentrenados son m√°s que simples ‚Äúatajos‚Äù: son bases de conocimiento visual general.  
> La diferencia de rendimiento entre entrenar desde cero y ajustar un modelo como EfficientNet demuestra el valor de la reutilizaci√≥n de conocimiento.

**Aprendizajes:**
- Cu√°ndo usar modelos ligeros (MobileNet) o pesados (ResNet/VGG).  
- C√≥mo controlar el *overfitting* con regularizaci√≥n y augmentaci√≥n.  
- Importancia de *fine-tuning selectivo* para no destruir pesos √∫tiles.

---

## üìö Evidencias

- Notebook ejecutado en **Google Colab**.  
- Im√°genes:
  - Batch de dataset inicial.
  - Gr√°ficos de validaci√≥n.
  - Matrices de confusi√≥n.
  - Comparaci√≥n global.  

[![Abrir Notebook en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/10EO20TRSvEH29ZpbuqLtJALkW687Vzdm?usp=sharing)
