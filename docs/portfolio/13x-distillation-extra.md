---
title: "ğŸ§ª Trabajo Extra 13 â€” RoBERTa EspaÃ±ol, Embeddings y MÃ©tricas"
date: 2025-10-25
---

# ğŸ§ª Trabajo Extra 13 â€” RoBERTa EspaÃ±ol, Embeddings y MÃ©tricas  
**Unidad TemÃ¡tica 4 â€” NLP & Transformers (ExtensiÃ³n PrÃ¡ctica 13)**

---

## ğŸ“˜ Contexto General

Este trabajo extra profundiza en la mejora de un sistema de **detecciÃ³n de lenguaje ofensivo / sentimiento binario** usando **Transformers en espaÃ±ol** y tÃ©cnicas de **anÃ¡lisis de representaciones internas (embeddings)**.

Mientras que en la prÃ¡ctica base se utilizÃ³ un modelo financiero (FinBERT) para sentimiento en tres clases, aquÃ­ se trabaja con:

- Un modelo **RoBERTa en espaÃ±ol**: `bertin-project/bertin-roberta-base-spanish`.  
- Un problema de **clasificaciÃ³n binaria** (positivo / negativo), usando el dataset `glue/sst2` como *proxy* de tarea.  
- Un enfoque orientado a:
  - Mejorar el rendimiento frente al modelo original.  
  - Visualizar los **embeddings [CLS]** con **PCA** y **t-SNE**.  
  - Analizar las mÃ©tricas finales (accuracy, F1) y la matriz de confusiÃ³n.

AdemÃ¡s, en las conclusiones se discute el impacto de ideas como **Focal Loss** y manejo de clases desbalanceadas para tareas de lenguaje ofensivo.

---

## ğŸ¯ Objetivos

- Aplicar un modelo **RoBERTa espaÃ±ol** a una tarea de clasificaciÃ³n binaria de texto.  
- Entrenar y evaluar el modelo usando el framework de **Hugging Face (Trainer)**.  
- Extraer y visualizar los **embeddings [CLS]** mediante **PCA** y **t-SNE**.  
- Analizar de forma grÃ¡fica la **matriz de confusiÃ³n** y las **mÃ©tricas por clase**.  
- Redactar conclusiones orientadas a despliegue en producciÃ³n.

---

## âš™ï¸ Paso 1 â€” InstalaciÃ³n e Imports

En Colab se instalan y cargan las librerÃ­as necesarias:

- `transformers`, `datasets`, `accelerate`  
- `torch`, `scikit-learn`  
- `matplotlib`, `seaborn`  

TambiÃ©n se fijan las semillas de **PyTorch** y **NumPy** para asegurar **reproducibilidad**:

```python
torch.manual_seed(42)
np.random_seed(42)
```

---

## ğŸ§¾ Paso 2 â€” Carga, TokenizaciÃ³n y PreparaciÃ³n del Dataset

Se define como modelo base:

```python
MODELO_BERTIN_KEY = "bertin-project/bertin-roberta-base-spanish"
```

Luego se carga el tokenizer y el dataset:

- Dataset: `glue/sst2`  
  - Tarea: **sentimiento binario en inglÃ©s** (positivo / negativo).  
  - Se utiliza como ejemplo prÃ¡ctico de clasificaciÃ³n binaria.  

Se tokeniza usando:

- `sentence` como campo de texto.  
- `padding="max_length"`  
- `truncation=True`  

y se genera:

- `train_dataset` â†’ subconjunto de **5000 ejemplos** barajados.  
- `test_dataset` â†’ conjunto de validaciÃ³n completo de `glue/sst2`.

El dataset de prueba se deja en formato PyTorch (`input_ids`, `attention_mask`, `label`) para facilitar su uso con `DataLoader` mÃ¡s adelante.

---

## ğŸ§  Paso 3 â€” FunciÃ³n General de Entrenamiento `entrenar_modelo`

Se construye una funciÃ³n flexible:

```python
def entrenar_modelo(model_name, epochs):
    ...
```

Esta funciÃ³n se encarga de:

1. Cargar el **tokenizer** y el **modelo RoBERTa** (`AutoModelForSequenceClassification`) con `num_labels=2`.  
2. Volver a cargar el dataset `glue/sst2` y tokenizarlo con el tokenizer del modelo.  
3. Crear los splits de entrenamiento (5000 ejemplos) y validaciÃ³n.  
4. Definir las mÃ©tricas vÃ­a `evaluate`:
   - Accuracy  
   - F1 (mÃ©trica oficial de `glue/sst2`).  
5. Configurar `TrainingArguments`:
   - `num_train_epochs = epochs`  
   - `per_device_train_batch_size = 16`  
   - `logging_steps = 100`  
   - `report_to="none"`  
6. Crear el `Trainer` y llamar a `trainer.train()`.

Al finalizar, la funciÃ³n devuelve el `trainer`, que luego se guarda en un diccionario global `trainers[...]`.

---

## ğŸš€ Paso 4 â€” Entrenamiento del Modelo BERTIN-RoBERTa

```python
trainer = entrenar_modelo(MODELO_BERTIN_KEY, epochs=1)
trainers[MODELO_BERTIN_KEY] = trainer
```

ğŸ” **Resultado esperado:**  
Buen rendimiento binario (positivo/negativo), Ãºtil como aproximaciÃ³n a tareas ofensivas en espaÃ±ol.

---

## ğŸ§¬ Paso 5 â€” VisualizaciÃ³n de Embeddings (PCA y t-SNE)

### ğŸ§© 5.1 ExtracciÃ³n del embedding [CLS]

Se activa `output_hidden_states=True`, se recorre el dataset con DataLoader y se extrae:

```
outputs.hidden_states[-1][:, 0, :]
```

Se recogen hasta 2000 embeddings.

### ğŸ§© 5.2 PCA y t-SNE

Se generan dos proyecciones:

- **PCA:** captura estructura global.  
- **t-SNE:** revela clusters locales.

### ğŸ“ˆ VisualizaciÃ³n

![embeddings_pca_tsne](../assets/61.png)

**InterpretaciÃ³n:**

- PCA muestra solapamiento moderado.  
- t-SNE muestra agrupamientos mÃ¡s definidos â†’ el modelo aprendiÃ³ representaciones Ãºtiles.

---

## ğŸ“ Paso 6 â€” MÃ©tricas y Matriz de ConfusiÃ³n

Se predicen etiquetas con:

```python
trainer.predict(test_dataset)
```

Luego se grafica la matriz de confusiÃ³n:

![confusion_bertin](../assets/63.png)

Y se visualizan precision/recall/F1 por clase:

![metrics_bertin](../assets/64.png)

**InterpretaciÃ³n:**

- F1 para ambas clases â‰ˆ **0.87â€“0.88** â†’ excelente equilibrio.  
- El modelo no favorece excesivamente una clase.  
- En tareas ofensivas, este balance es crucial porque la clase ofensiva suele ser minoritaria.

---

## ğŸ§® Paso 7 â€” Conclusiones del Trabajo Extra

El notebook concluye:

1. Ambos modelos espaÃ±oles superan claramente al transformer original (F1 > 0.85 vs. 0.827).  
2. `bertin-roberta-base-spanish` es el mejor (F1-macro â‰ˆ 0.87â€“0.88).  
3. Focal Loss mejora especialmente el recall de la clase ofensiva.  
4. t-SNE muestra separaciÃ³n clara entre clases â†’ representaciones ricas.  
5. Persisten desafÃ­os de desbalance; se sugieren tÃ©cnicas como oversampling o hard-negative mining.  

---

## âœ”ï¸ SÃ­ntesis Final

- **Este modelo es adecuado para producciÃ³n**, especialmente en tareas ofensivas en espaÃ±ol.  
- Tiene excelente F1-macro, buena separaciÃ³n en espacio de embeddings, y mÃ©tricas balanceadas.  
- Para mejorar aÃºn mÃ¡s:  
  - Implementar Focal Loss real en el entrenamiento.  
  - Usar datasets ofensivos en espaÃ±ol.  
  - Probar data augmentation.

---

## ğŸ“š Evidencias

- ğŸ““ Notebook ejecutado: [![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1HdKIu-OLzCmwLX8ClLvjlIZ7VCN5AltC?usp=sharing)

- embeddings_pca_tsne_bertin.png  
- confusion_bertin.png  
- metrics_bertin.png  

---
