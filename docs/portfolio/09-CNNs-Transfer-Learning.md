---
title: "PrÃ¡ctica 9 â€” CNNs y Transfer Learning con TensorFlow/Keras"
date: 2025-01-01
---

# ğŸ§  PrÃ¡ctica 9 â€” De CNNs desde cero a Transfer Learning
**Unidad 3 â€” Computer Vision**

En esta prÃ¡ctica pasamos de redes convolucionales construidas desde cero a modelos pre-entrenados usando **TensorFlow / Keras**, aplicados a un problema realista de clasificaciÃ³n de imÃ¡genes.

El foco no es solo â€œentrenar un modeloâ€, sino **entender las decisiones arquitectÃ³nicas**, comparar enfoques y reflexionar sobre cuÃ¡ndo usar cada uno.

---

## ğŸ¯ Objetivos de la prÃ¡ctica

- Comprender la estructura bÃ¡sica de una **Red Neuronal Convolucional (CNN)**.
- Implementar una CNN *from scratch* para clasificaciÃ³n de imÃ¡genes.
- Aplicar **Transfer Learning** con un modelo pre-entrenado (ej. `VGG16` / `ResNet50`) usando `keras.applications`.
- Comparar desempeÃ±o: modelo simple vs modelo pre-entrenado.
- Analizar resultados con curvas de entrenamiento, matriz de confusiÃ³n y ejemplos de predicciones.

---

## ğŸ“¦ Dataset y contexto

Para esta prÃ¡ctica se utilizÃ³ un dataset de **clasificaciÃ³n de imÃ¡genes** con mÃºltiples clases (por ejemplo, subconjunto de *Food-101* o un dataset similar preparado para la tarea).  
Cada imagen representa una categorÃ­a visual (clase), y el objetivo es predecir correctamente su etiqueta.

**Ejemplos de clases posibles:**

- pastas, hamburguesas, ensaladas, postresâ€¦
- o categorÃ­as equivalentes del dataset trabajado en el notebook.



**InterpretaciÃ³n:**

- Se observa diversidad de clases.
- Variaciones de iluminaciÃ³n, Ã¡ngulos y fondos â†’ justifican usar CNNs y data augmentation.
- El dataset es suficientemente complejo para que un modelo lineal no sea suficiente.

---

## ğŸ”§ Setup bÃ¡sico

Uso de `ImageDataGenerator` para reescalar y aplicar *data augmentation* ligera.

```python
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)
```

**Punto clave:** separamos *train/val* correctamente desde el generador, evitando data leakage.

---

## ğŸ§± Modelo 1 â€” CNN desde cero

Se construye una CNN sencilla como baseline.

![Curvas CNN bÃ¡sica](../assets/cnn02.png)

**InterpretaciÃ³n:**

- La accuracy de entrenamiento sube rÃ¡pido, la de validaciÃ³n se estabiliza antes.
- Si la brecha `train_acc >> val_acc` crece demasiado â†’ posible overfitting.
- Como baseline, funciona pero tiene lÃ­mites: tarda mÃ¡s en aprender patrones complejos.

---

## ğŸš€ Modelo 2 â€” Transfer Learning con modelo pre-entrenado

Se congela la base convolucional de un modelo pre-entrenado en ImageNet y se aÃ±aden capas densas finales.

![Curvas Transfer Learning](../assets/cnn03.png)

**ComparaciÃ³n:**

- Transfer Learning suele alcanzar:
  - Mayor accuracy de validaciÃ³n.
  - Mejor estabilidad.
  - Menos epochs para converger.
- Usa representaciones aprendidas en millones de imÃ¡genes â†’ ventaja clara frente a entrenar desde cero con dataset pequeÃ±o.

---

## ğŸ§ Comparando modelos

**Ejemplo de resumen numÃ©rico:**

| Modelo                  | Val. Accuracy aprox. | Comentario                     |
|-------------------------|----------------------|--------------------------------|
| CNN desde cero          | 0.70â€“0.78            | Aprende, pero sufre con ruido |
| Transfer Learning (VGG) | 0.80â€“0.90+           | Mejor generalizaciÃ³n           |

![Ejemplos de predicciones](../assets/cnn01.png)

**InterpretaciÃ³n:**

- Analizar dÃ³nde falla el modelo â†’ clases muy similares visualmente, poca iluminaciÃ³n, imÃ¡genes borrosas.
- Ãštil para decidir si necesitamos mÃ¡s datos, mayor resoluciÃ³n o fine-tuning adicional.

---

## ğŸ§  Conclusiones clave

1. **La CNN bÃ¡sica** sirve como referencia.
2. **El modelo con Transfer Learning** logra mejor desempeÃ±o con menos datos y menos tiempo.
3. **Buenas prÃ¡cticas:** separaciÃ³n train/val, data augmentation, uso de softmax + `categorical_crossentropy`.

---

## ğŸ“ ReflexiÃ³n personal

- EntendÃ­ cÃ³mo una CNN â€œveâ€ una imagen a travÃ©s de filtros y mapas de activaciÃ³n.
- Ver la diferencia real entre entrenar desde cero y usar Transfer Learning me mostrÃ³ por quÃ© en la industria casi siempre se parte de modelos pre-entrenados.
- PrÃ³ximos pasos: explorar fine-tuning parcial, aumentar resoluciÃ³n y Grad-CAM.

---

## ğŸ“š Evidencias

- Notebook en Google Colab con todo el cÃ³digo ejecutado.  
- Capturas de:
  - Batch de imÃ¡genes del dataset.
  - Curvas de entrenamiento (loss/accuracy) de ambos modelos.
  - Cuadros comparativos y predicciones ejemplo.

[![Abrir Notebook en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1VFvHlWs6KEEUCObKoH_rJnrnbCPAN9V0?usp=sharing)
