---
title: "ğŸŒº PrÃ¡ctica 10 â€” Data Augmentation Avanzado & Explicabilidad (Flowers102)"
date: 2025-01-01
---

# ğŸŒº PrÃ¡ctica 10 â€” Data Augmentation Avanzado & Explicabilidad (Flowers102)

## ğŸ¯ Contexto

Una aplicaciÃ³n mÃ³vil de **identificaciÃ³n de flores** para jardineros, botÃ¡nicos aficionados y educadores necesita clasificar automÃ¡ticamente **102 especies de flores**.

Las imÃ¡genes provienen de usuarios en condiciones reales:

- IluminaciÃ³n natural y artificial.
- Ãngulos variados.
- Fondos complejos (tierra, pasto, paredes, otras plantas).
- Diferentes etapas de floraciÃ³n.

### Objetivos del modelo

1. Clasificar correctamente **102 especies de flores** con buena precisiÃ³n.
2. Ser **robusto** ante variaciones de captura (luz, Ã¡ngulo, fondo).
3. Ofrecer **explicaciones visuales** de sus predicciones (para confianza y validaciÃ³n).

### CaracterÃ­sticas del dataset (Flowers102)

- 102 clases (especies de flores).
- ImÃ¡genes RGB, tamaÃ±os variables.
- Entre ~40 y ~250 imÃ¡genes por clase â†’ **dataset desbalanceado**.
- Alta variabilidad visual (iluminaciÃ³n, fondo, escala, enfoque).

### Valor para el negocio

- Democratizar el conocimiento botÃ¡nico vÃ­a una app accesible.
- Apoyar a **jardineros, estudiantes y docentes**.
- Mejorar la **confiabilidad** gracias a explicabilidad visual (Grad-CAM u otros).

---

## ğŸ§± Paso 1 â€” Setup (resumen tÃ©cnico)

```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, applications

import matplotlib.pyplot as plt
import numpy as np
import os, pathlib, random
```

ParÃ¡metros clave que se usan en la prÃ¡ctica:

- `IMG_SIZE = (224, 224)`
- `BATCH_SIZE = 32`
- `NUM_CLASSES = 102`

---

## ğŸŒ¼ Paso 2 â€” Carga y organizaciÃ³n del dataset

El dataset se estructura de la siguiente manera:

```text
data/
  train/
    class_01/
    class_02/
    ...
  val/
    class_01/
    ...
  test/
    class_01/
    ...
```

ğŸ“Œ **Aspectos importantes:**

- Se separan los conjuntos `train`, `val` y `test` evitando *data leakage*.
- NormalizaciÃ³n con `preprocess_input` del modelo base.
- Mezcla aleatoria solo para entrenamiento (`shuffle=True`).

---

## ğŸ¨ Paso 3 â€” Data Augmentation para robustez

Bloque de transformaciones aplicadas:

```python
data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.15),
    layers.RandomZoom(0.1),
    layers.RandomContrast(0.1),
], name="data_augmentation")
```

ğŸ“· **Ejemplo visual:**  
![Ejemplo de data augmentation en flores](../assets/fl01.png)
![Ejemplo de data augmentation en flores](../assets/fl02.png)
**InterpretaciÃ³n:**  
El modelo se expone a diferentes versiones visuales de las mismas flores, aumentando su capacidad de generalizaciÃ³n frente a cambios de entorno y cÃ¡mara.

---

## ğŸ§  Paso 4 â€” Modelo base con Transfer Learning

Se utiliza **EfficientNetB0** preentrenada en *ImageNet* como extractor de caracterÃ­sticas:

```python
base_model = applications.EfficientNetB0(
    include_top=False, weights="imagenet", input_shape=(224, 224, 3)
)
base_model.trainable = False

inputs = keras.Input(shape=(224, 224, 3))
x = data_augmentation(inputs)
x = applications.efficientnet.preprocess_input(x)
x = base_model(x, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3)(x)
outputs = layers.Dense(NUM_CLASSES, activation="softmax")(x)
model = keras.Model(inputs, outputs)
```
![Resultados evaluacion del modelo](../assets/fl04.png)
---

## ğŸ“ˆ Paso 5 â€” Resultados (baseline vs augmentado)

| ConfiguraciÃ³n                              | Val Accuracy aprox. | Comentario clave                          |
|--------------------------------------------|----------------------|-------------------------------------------|
| Base congelada, sin augmentation           | ~0.45â€“0.50           | Aprende poco, se sobreajusta rÃ¡pido.      |
| Base congelada + data augmentation         | ~0.55â€“0.60           | Mejor generalizaciÃ³n, menos sobreajuste.  |
| Fine-tuning parcial + augmentation         | ~0.60+               | Mejores features, requiere cuidado.       |



**ConclusiÃ³n:**  
El *data augmentation* estabiliza la curva de validaciÃ³n y mejora la precisiÃ³n sin aumentar el tamaÃ±o del dataset.

---

## ğŸ” Paso 6 â€” Explicabilidad con Grad-CAM

### MÃ©todo

1. Tomar una imagen de validaciÃ³n.  
2. Predecir con el modelo.  
3. Calcular Grad-CAM sobre la Ãºltima capa convolucional.  
4. Superponer el mapa sobre la imagen original.

ğŸ“Š **Ejemplo visual:**  

![Grad-CAM ](../assets/fl05.png)
![INTEGRATED GRADIENTS](../assets/fl05.png)
**InterpretaciÃ³n:**  
Las activaciones se concentran en pÃ©talos y estructuras relevantes.  
Esto valida que el modelo no depende del fondo y aprende patrones botÃ¡nicos reales.

---

## ğŸš€ Paso 7 â€” MIXUP & CUTMIX (TÃ©cnicas Avanzadas) 

Basado en papers oficiales:
   â€¢ Mixup  â†’ https://arxiv.org/abs/1710.09412
   â€¢ CutMix â†’ https://arxiv.org/abs/1905.04899
   
Visualizacion de Ejemplos generados>>>
![MIXUP ](../assets/fl02.png)
![CUTMIX ](../assets/fl03.png)
### ğŸ”¹ Otras arquitecturas

```python
models_to_test = [
    "ResNet50", "ResNet101", "ResNet152",
    "VGG16", "VGG19",
    "EfficientNetB0", "EfficientNetB3",
    "MobileNetV2", "MobileNetV3Large"
]
```

Comparar: precisiÃ³n, tiempo de entrenamiento, interpretabilidad y mapas Grad-CAM.

### ğŸ”¹ MÃ¡s augmentations

- Rotaciones agresivas  
- Crop aleatorio  
- Blur suave  
- Ajuste de color avanzado

### ğŸ”¹ Otros datasets sugeridos

- **PlantVillage** (enfermedades de plantas)  
- **Cats vs Dogs** (binario)  


---

## ğŸ§  ReflexiÃ³n final



- El **data augmentation** es clave para robustez y generalizaciÃ³n.  
- **Transfer Learning** acelera la convergencia sin grandes costos de cÃ³mputo.  
- **Grad-CAM** ofrece interpretabilidad y confianza para los usuarios finales.  

> â€œComprender cÃ³mo ve el modelo es tan importante como aumentar su precisiÃ³n.  
> Esta prÃ¡ctica me permitiÃ³ ver la IA como una herramienta confiable y explicable.â€

---

## ğŸ“š Evidencias

- Ejemplos de *data augmentation* y *Grad-CAM*.  
- Curvas de pÃ©rdida y precisiÃ³n.  
- Notebook ejecutado en Google Colab.

[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1vcJYmPHKdVeRVYCK23RVPnOVqAw4bCab?usp=sharing)
