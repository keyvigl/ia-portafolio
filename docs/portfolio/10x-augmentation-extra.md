---
title: "PrÃ¡ctica 10x â€” Transfer Learning, Mixup y Grad-CAM++ en Oxford-IIIT Pets"
date: 2025-01-01
---

# ğŸ§  PrÃ¡ctica 10x â€” Transfer Learning, Mixup y Grad-CAM++ en Oxford-IIIT Pets

## ğŸ¯ Objetivo

Entrenar y evaluar un modelo de clasificaciÃ³n de imÃ¡genes que combine:
- **Transfer Learning (EfficientNetB0 preentrenado)**  
- **TÃ©cnicas de regularizaciÃ³n avanzada**: Mixup, CutMix y Data Augmentation  
- **Explicabilidad visual con Grad-CAM++**  
- **VisualizaciÃ³n de embeddings y mÃ©tricas globales**

Todo esto sobre el dataset **Oxford-IIIT Pets**, con clases balanceadas de gatos y perros de distintas razas.

---

## ğŸ“¦ Paso 1 â€” ConfiguraciÃ³n general

```python
DATASET_NAME = "oxford_iiit_pet"
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 5
USE_MIXUP = True
USE_CUTMIX = True
USE_TTA = True
```

> Se utilizÃ³ una configuraciÃ³n reproducible (`tf.random.set_seed(42)`), y el entrenamiento se ejecutÃ³ en **Google Colab** con GPU habilitada.

---

## ğŸ¶ Dataset: Oxford-IIIT Pets

- 37 clases de razas de gatos y perros.  
- TamaÃ±os de imagen variables (mayoritariamente RGB 200â€“400px).  
- Dataset balanceado y con buena calidad visual.

ğŸ“Š **Divisiones:**
| Split | Porcentaje | PropÃ³sito |
|-------|-------------|------------|
| Train | 80% | Entrenamiento |
| Val | 20% | ValidaciÃ³n |
| Test | 100% | EvaluaciÃ³n final |


---

## ğŸ§¹ Paso 2 â€” Preprocesamiento y Augmentation

Se aplicaron transformaciones visuales moderadas para mejorar la robustez sin alterar la identidad del animal.

```python
data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.05),
    layers.RandomZoom(0.1),
])
```


**InterpretaciÃ³n:**  
Estas variaciones permiten al modelo aprender invariancias de posiciÃ³n, orientaciÃ³n y escala.

---

## ğŸ§ª Paso 3 â€” Mixup y CutMix

**Mixup** genera imÃ¡genes interpoladas combinando pÃ­xeles y etiquetas de dos muestras.  
**CutMix** reemplaza un recorte rectangular por un fragmento de otra imagen, mezclando etiquetas proporcionalmente.

ğŸ“Š **FÃ³rmulas:**
\[
\tilde{x} = \lambda x_i + (1-\lambda)x_j
\]
\[
\tilde{y} = \lambda y_i + (1-\lambda)y_j
\]

ğŸ“· **Ejemplos de entrenamiento:**
![mixup-cutmix-examples](../assets/x01.png)

**Ventajas observadas:**
- Aumenta la diversidad de entrenamiento.  
- Regulariza las fronteras de decisiÃ³n.  
- Reduce el sobreajuste en datasets medianos.

---

## ğŸ§± Paso 4 â€” Arquitectura del modelo

**Base:** EfficientNetB0 preentrenado en ImageNet.  
**Cabeza:** Global Average Pooling + Dropout + Dense Softmax.

```python
x = base_model(inputs, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3)(x)
outputs = layers.Dense(num_classes, activation="softmax")(x)
```

ğŸ“Š **Resumen del modelo:**
| Bloque | DescripciÃ³n |
|---------|-------------|
| Backbone | EfficientNetB0 |
| RegularizaciÃ³n | Dropout 0.3 |
| Optimizador | Adam (LR = 1e-3) |
| PÃ©rdida | Categorical Crossentropy |

---

## ğŸš€ Paso 5 â€” Entrenamiento y validaciÃ³n

ğŸ“ˆ **Curvas de entrenamiento:**
![training-curves](../assets/x02.png)

| Fase | Accuracy (Train) | Accuracy (Val) | ObservaciÃ³n |
|------|-------------------|----------------|--------------|
| Inicial | 0.80 | 0.76 | Buen punto de partida con backbone congelado. |
| Final | 0.91 | 0.86 | Mejoras con Mixup + CutMix y Dropout. |

**ConclusiÃ³n:**  
El modelo alcanzÃ³ un rendimiento estable sin sobreajuste, demostrando la efectividad de las tÃ©cnicas de mezcla.

---

## ğŸ§ª Paso 6 â€” EvaluaciÃ³n con TTA (Test-Time Augmentation)

El modelo fue evaluado aplicando rotaciones y flips en inferencia, promediando los resultados.

ğŸ“ˆ **Ejemplo de comparaciÃ³n:**

| Muestra | PredicciÃ³n Normal | PredicciÃ³n TTA |
|----------|-------------------|----------------|
| bengal cat | bengal cat | âœ… bengal cat |
| samoyed | beagle | âœ… samoyed |

> TTA aportÃ³ una mejora del **+2% en precisiÃ³n** promedio.

---

## ğŸ” Paso 7 â€” Explicabilidad con Grad-CAM++

El mÃ©todo **Grad-CAM++** genera mapas de calor de activaciÃ³n para visualizar quÃ© regiones de la imagen activan las neuronas finales del modelo.

ğŸ“· **Ejemplo de interpretaciÃ³n:**
![gradcam-example](../assets/x04.png)

**Observaciones:**
- Las regiones activadas corresponden al rostro y pelaje del animal.  
- Confirma que el modelo enfoca su atenciÃ³n en rasgos semÃ¡nticamente relevantes (ojos, hocico, textura).  

ğŸ“Š **ComparaciÃ³n:**
| MÃ©todo | Resultado |
|---------|-----------|
| Grad-CAM | Mapas mÃ¡s difusos. |
| Grad-CAM++ | Mayor precisiÃ³n espacial y diferenciaciÃ³n de bordes. |

---

## ğŸ§® Paso 8 â€” Matriz de confusiÃ³n y reporte

![confusion-matrix](../assets/x03.png)

```text
PrecisiÃ³n media: 0.86
Recall macro: 0.84
F1-score global: 0.85
```

ğŸ“Š **Top-5 Predicciones:**
![top5-plot](../assets/x05.png)

> El modelo rara vez confunde especies distintas; los errores ocurren entre razas visualmente similares (por ejemplo, retrievers).

---

## ğŸŒŒ Paso 9 â€” t-SNE de Embeddings

Se extrajeron caracterÃ­sticas del backbone y se redujeron a 2D mediante **t-SNE** para visualizar la separaciÃ³n entre clases.

ğŸ“ˆ **Resultado:**
![tsne-pets](../assets/x06.png)

**InterpretaciÃ³n:**  
Las clases se agrupan claramente por especie (gato/perro) y textura, evidenciando buena capacidad discriminativa del modelo.

---

## ğŸ”§ Paso 10 â€” Sensibilidad al learning rate

ğŸ“Š **Curva de LR experimental:**
![lr-curve](../assets/x07.png)

- El mejor desempeÃ±o se obtuvo alrededor de **1e-4 a 1e-3**.  
- Tazas mayores (1e-2) degradan la estabilidad.

---

## ğŸ’¬ ReflexiÃ³n personal

> â€œEsta prÃ¡ctica consolidÃ³ mi entendimiento sobre cÃ³mo la combinaciÃ³n de **transfer learning, regularizaciÃ³n visual y explicabilidad** permite desarrollar modelos de visiÃ³n robustos y transparentes.  
> Implementar Grad-CAM++ me ayudÃ³ a comprender el porquÃ© detrÃ¡s de cada predicciÃ³n, algo clave para construir IA responsable.â€

---

## ğŸš€ Conclusiones generales

1. **EfficientNetB0** sigue siendo una opciÃ³n potente y eficiente para Transfer Learning.  
2. **Mixup y CutMix** ofrecen una regularizaciÃ³n natural en datasets medianos.  
3. **TTA** y **Grad-CAM++** mejoran la robustez y la transparencia.  
4. La combinaciÃ³n de todas estas tÃ©cnicas logra un sistema visual confiable y explicable.

---

## ğŸ“š Evidencias y archivos

- ğŸ““ Notebook ejecutado:[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1RtNclkvJs04rGltVIDcLrGxdhCKIhBK3?usp=sharing)
- ğŸ“· GrÃ¡ficas incluidas:
  - Augmentation
  - Mixup/CutMix
  - Curvas de pÃ©rdida/accuracy
  - Grad-CAM++
  - Confusion Matrix
  - t-SNE embeddings
- ğŸ’¾ Modelo guardado: `efficientnet_pets_mixup.h5`

---

## ğŸ“˜ Referencias

- [Grad-CAM++ Original Paper (Chattopadhyay et al., 2018)](https://arxiv.org/abs/1710.10063)  
- [Keras Documentation â€” EfficientNet](https://keras.io/api/applications/efficientnet/)  
- [TensorFlow Image Augmentation Tutorial](https://www.tensorflow.org/tutorials/images/data_augmentation)  
- [Mixup: Beyond Empirical Risk Minimization (Zhang et al., 2018)](https://arxiv.org/abs/1710.09412)

---
