---
title: "ğŸ§ª PrÃ¡ctica 13 â€” Fine-tuning de Transformers para Sentimiento Financiero"
date: 2025-10-15
---

# ğŸ§ª PrÃ¡ctica 13 â€” Fine-tuning de Transformers para Sentimiento Financiero  
**Unidad TemÃ¡tica 4 â€” NLP & Transformers**

---

## ğŸ“˜ Contexto General

En esta prÃ¡ctica se trabaja con el dataset  
`zeroshot/twitter-financial-news-sentiment`, que contiene **tweets/noticias financieras en inglÃ©s** etiquetadas en **tres clases**:

- `0` â†’ Bearish (sentimiento negativo)  
- `1` â†’ Bullish (sentimiento positivo)  
- `2` â†’ Neutral  

El objetivo es **construir, analizar y comparar** dos enfoques de modelado de texto:

1. Un **baseline clÃ¡sico**: `TF-IDF + RegresiÃ³n LogÃ­stica`.  
2. Un modelo **Transformer preentrenado orientado a finanzas** (FinBERT), ajustado mediante *fine-tuning*.  

MÃ¡s que obtener el mejor score, se busca **entender el impacto** de:

- La **representaciÃ³n del texto** (bolsa de palabras vs. embeddings contextuales).  
- El **desbalance de clases** en las mÃ©tricas.  
- El comportamiento del entrenamiento y la validaciÃ³n (posible **overfitting**).  

---

## ğŸ¯ Objetivos

- Explorar el dataset de noticias financieras: longitudes de texto, distribuciÃ³n de clases y vocabulario tÃ­pico.  
- Construir un **modelo baseline** con `TF-IDF + LogisticRegression`.  
- Entrenar un modelo **Transformer (FinBERT)** para clasificaciÃ³n en 3 clases.  
- Comparar el rendimiento de ambos enfoques en tÃ©rminos de **accuracy** y **F1-score macro**.  
- Analizar visualmente:
  - La **distribuciÃ³n de longitudes** y de clases.  
  - La **separabilidad** mediante proyecciones (PCA/UMAP).  
  - La **matriz de confusiÃ³n** del baseline.  
  - Las **curvas de validaciÃ³n** del Transformer.  

---

## âš™ï¸ Paso 1 â€” Setup y Carga del Dataset

Se realiza el setup inicial en Colab:

- InstalaciÃ³n de librerÃ­as:  
  `transformers`, `datasets`, `evaluate`, `scikit-learn`, `matplotlib`, `seaborn`, `wordcloud`, `accelerate`, `gensim`, `umap-learn`.  
- FijaciÃ³n de semilla (`SEED = 42`) para garantizar **reproducibilidad**.  
- Carga del dataset con `load_dataset("zeroshot/twitter-financial-news-sentiment")`.

Se normalizan las columnas a:

```
text
label
```

y se eliminan valores nulos.

---

## ğŸ“Š Paso 2 â€” DistribuciÃ³n de Longitud de Textos

Se calcula la longitud de cada texto (en tokens) y se grafica un histograma.

![longitud_tokens](../assets/wo01.png)

**InterpretaciÃ³n:**

- La mayorÃ­a de textos contiene entre **10 y 30 tokens**.  
- Se puede usar un `max_length` de **32â€“64 tokens** sin perder informaciÃ³n.  
- Reducir el `max_length` reduce el costo computacional.

---

## âš–ï¸ Paso 3 â€” DistribuciÃ³n de Clases

![distribucion_clases](../assets/wo02.png)

**InterpretaciÃ³n:**

- La clase **Neutral (2)** domina fuertemente.  
- Esto distorsiona mÃ©tricas como el accuracy.  
- Se usarÃ¡ **F1 macro** para evaluar imparcialmente.

---

## ğŸ§© Paso 4 â€” N-grams y WordClouds por Clase

Se generan n-grams por clase usando `CountVectorizer`.  
Luego, se construyen WordClouds para visualizar vocabulario dominante.

### WordCloud Clase 0 (Bearish)
![wc0](../assets/wo03.png)

### WordCloud Clase 1 (Bullish)
![wc1](../assets/wo04.png)

### WordCloud Clase 2 (Neutral)
![wc2](../assets/wo05.png)

**InterpretaciÃ³n:**

- Aparecen tickers (`$TSLA`, `$AAPL`), verbos bursÃ¡tiles (â€œdowngradeâ€, â€œbeatâ€, â€œslidesâ€), y URLs.  
- El dataset contiene bastante **ruido financiero**.  
- Bullish muestra verbos positivos; Bearish, verbos negativos.  
- Neutral estÃ¡ dominado por descripciones de mercado.

---

## ğŸ”¬ Paso 5 â€” Proyecciones (PCA / UMAP) + Word2Vec

### PCA sobre TF-IDF
![pca](../assets/wo06.png)

### UMAP sobre TF-IDF
![umap](../assets/wo07.png)

**InterpretaciÃ³n:**

- Las clases no se separan bien en un espacio superficial como TF-IDF.  
- El sentimiento no estÃ¡ determinado por palabras individuales sino por **contexto**.  
- El ruido financiero hace mÃ¡s difÃ­cil la separaciÃ³n.

### Word2Vec  
El modelo captura relaciones de mercado (cuando hay frecuencia suficiente), pero en general reflejÃ³ mÃ¡s limitaciones por el tipo de corpus.

---

## ğŸ§± Paso 6 â€” Baseline: TF-IDF + LogisticRegression

Se entrena un modelo clÃ¡sico con:

```
TfidfVectorizer(max_features=30000, ngram_range=(1,2))
LogisticRegression(max_iter=200)
```

### Matriz de ConfusiÃ³n
![confusion](../assets/wo08.png)

### Resultados aproximados del baseline

- **Accuracy â‰ˆ 0.80**  
- **F1 macro â‰ˆ 0.68**

**InterpretaciÃ³n:**

- Detecta muy bien la clase Neutral.  
- Confunde muchas instancias Bearish/Bullish con Neutral.  
- TF-IDF no capta matices del sentimiento financiero.

---

## ğŸ¤– Paso 7 â€” Fine-tuning de FinBERT

Se entrena un Transformer especializado en finanzas con:

- LR = 2e-5  
- batch = 16  
- epochs = 4  
- weight decay = 0.01  
- `metric_for_best_model = "f1"`

### Resultados del Transformer

- **Accuracy â‰ˆ 0.872**  
- **F1 macro â‰ˆ 0.827**

**InterpretaciÃ³n:**

- Mejora sustancial respecto al baseline.  
- El modelo entiende mejor matices sutiles del lenguaje financiero.  
- Aun asÃ­, aparece ligero **overfitting** en Ã©pocas avanzadas.

---

## ğŸ“ˆ Paso 8 â€” Curvas de ValidaciÃ³n del Transformer

![curvas](../assets/wo09.png)

**InterpretaciÃ³n:**

- F1 sube abruptamente en Ã©pocas 1 y 2.  
- ValidaciÃ³n comienza a estancarse y aumentar la pÃ©rdida â†’ **overfitting** a partir de la Ã©poca 3.  
- RecomendaciÃ³n: entrenar solo 2â€“3 Ã©pocas o activar early stopping.

---

## ğŸ¥‡ Paso 9 â€” ComparaciÃ³n Final



| Modelo | Accuracy | F1 macro | Comentario |
|--------|----------|----------|------------|
| Baseline (TF-IDF + LR) | ~0.80 | ~0.68 | Simple pero limitado |
| FinBERT | ~0.87 | ~0.83 | Mucho mejor para matices financieros |

**ConclusiÃ³n:**  
El Transformer supera ampliamente al modelo clÃ¡sico, especialmente en **clases minoritarias**.

---

## ğŸ’¬ Conclusiones Globales

1. El dataset es ruidoso y desbalanceado; requiere modelos robustos.  
2. TF-IDF funciona como baseline pero falla en Bearish/Bullish.  
3. FinBERT capta contexto y matices, logrando mejor rendimiento.  
4. Las proyecciones PCA/UMAP mostraron que el problema no es lineal.  
5. El entrenamiento demostrÃ³ seÃ±ales de overfitting moderado.  

---

## ğŸ¤” Preguntas de ReflexiÃ³n

- Â¿Por quÃ© F1 macro es una mÃ©trica mÃ¡s justa que accuracy aquÃ­?  
- Â¿En quÃ© casos seguirÃ­as usando TF-IDF en lugar de Transformers?  
- Â¿QuÃ© tipo de drift podrÃ­a aparecer en producciÃ³n?  
- Â¿CÃ³mo afectarÃ­a usar un modelo preentrenado en espaÃ±ol?  

---

## ğŸ“š Evidencias

- ğŸ““ Notebook ejecutado: [![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1HdKIu-OLzCmwLX8ClLvjlIZ7VCN5AltC?usp=sharing)

---

