---
title: "âš™ï¸ PrÃ¡ctica 03 â€” Extra: ValidaciÃ³n y SelecciÃ³n de Modelos (Diabetes Dataset)"
date: 2025-01-01
---

# âš™ï¸ PrÃ¡ctica 03 â€” Extra  
**ComparaciÃ³n de Modelos de RegresiÃ³n en Datos MÃ©dicos**

---

## ğŸ“Œ Contexto

En esta prÃ¡ctica complementaria se realiza una **evaluaciÃ³n comparativa de modelos de regresiÃ³n** para predecir la **progresiÃ³n de la diabetes** a partir de variables clÃ­nicas.  
El objetivo es seleccionar el modelo mÃ¡s **preciso y estable** mediante **validaciÃ³n cruzada (K-Fold)** y el anÃ¡lisis de mÃ©tricas.

**Dataset:** *Diabetes Dataset* de *scikit-learn* (442 registros, 10 variables).  
Incluye informaciÃ³n como **edad, IMC, presiÃ³n arterial, niveles sÃ©ricos y glucosa**.

---

## ğŸ¯ Objetivos

- Comparar modelos de regresiÃ³n:  
  **RegresiÃ³n Lineal**, **Ridge Regression**, **Random Forest Regressor**.  
- Evaluar rendimiento con validaciÃ³n cruzada (5-fold).  
- Analizar estabilidad con mÃ©tricas: **MAE**, **RMSE** y **RÂ²**.  
- Visualizar resultados mediante grÃ¡ficos comparativos.

---

## ğŸ§© MetodologÃ­a

1. **Carga del dataset:** Diabetes (scikit-learn).  
2. **Modelado:** Se construyeron pipelines con escalado y los modelos seleccionados.  
3. **EvaluaciÃ³n cruzada:** `KFold(n_splits=5, shuffle=True, random_state=42)`  
4. **MÃ©tricas:**  
   - MAE â†’ Error medio absoluto  
   - RMSE â†’ RaÃ­z del error cuadrÃ¡tico medio  
   - RÂ² â†’ Varianza explicada  

---

## ğŸ§  Modelos Evaluados

| Modelo | DescripciÃ³n |
|---------|--------------|
| **Linear Regression** | Modelo base para regresiÃ³n continua. |
| **Ridge Regression (L2)** | Variante regularizada que penaliza pesos grandes. |
| **Random Forest Regressor** | Ensamble de Ã¡rboles, robusto frente a ruido y relaciones no lineales. |

---

## ğŸ“ˆ Resultados Promedio (5-Fold CV)

| Modelo | MAE (â†“) | RMSE (â†“) | RÂ² (â†‘) |
|---------|----------|-----------|--------|
| **Random Forest** | 42.8 | 56.7 | **0.45** |
| **Ridge Regression** | 43.5 | 57.6 | 0.43 |
| **Linear Regression** | 43.9 | 58.1 | 0.42 |

ğŸ“Š *InterpretaciÃ³n:*  
El modelo **Random Forest** obtuvo el mejor desempeÃ±o general, con el menor error y el mayor coeficiente de determinaciÃ³n, mostrando mayor capacidad para capturar relaciones no lineales.

---

## ğŸ“Š VisualizaciÃ³n de Resultados

### ğŸ“¦ DistribuciÃ³n de errores (K-Fold CV)
Los grÃ¡ficos boxplot permiten observar la **variabilidad de las mÃ©tricas** entre las particiones.

![DistribuciÃ³n de MAE por modelo](../assets/extra19.png)  
![DistribuciÃ³n de RMSE por modelo](../assets/extra24.png)  
![DistribuciÃ³n de RÂ² por modelo](../assets/extra20.png)

ğŸ“Œ **Insight:**  
La dispersiÃ³n en los boxplots es reducida, lo que indica una **alta estabilidad** entre folds.  
El **Random Forest** presenta el mejor balance entre error y consistencia.

---

### ğŸ“Š Comparativa de rendimiento promedio

Para facilitar la interpretaciÃ³n, se muestran los valores promedio Â± desviaciÃ³n estÃ¡ndar de cada mÃ©trica.

![Comparativa de MAE promedio](../assets/extra21.png)  
![Comparativa de RMSE promedio](../assets/extra22.png)  
![Comparativa de RÂ² promedio](../assets/extra23.png)

ğŸ“ˆ Los grÃ¡ficos confirman que el **Random Forest** supera ligeramente a los modelos lineales, especialmente en RMSE.

---

## ğŸ”§ Ajuste de HiperparÃ¡metros

Se probÃ³ un **tuning bÃ¡sico** con `GridSearchCV` para explorar mejoras.

| Modelo | ParÃ¡metro Ajustado | Mejor Valor | RMSE |
|---------|-------------------|--------------|------|
| **Ridge** | Î± (penalizaciÃ³n L2) | 10.0 | 56.9 |
| **Random Forest** | Ãrboles (n_estimators) | 300 | **56.7** |

ğŸ’¡ Los ajustes confirmaron que el modelo base de **Random Forest** ya estaba bien calibrado.

---

## ğŸ’¬ InterpretaciÃ³n y ReflexiÃ³n

- **Modelos lineales**: interpretables pero limitados ante relaciones no lineales.  
- **Random Forest**: captura mejor la complejidad del fenÃ³meno mÃ©dico.  
- La **validaciÃ³n cruzada** permitiÃ³ garantizar estabilidad en los resultados.  
- Las **mÃ©tricas consistentes** sugieren buen desempeÃ±o sin overfitting.

---

## ğŸ§­ Conclusiones

- ğŸ¥‡ **Modelo ganador:** Random Forest Regressor.  
- **Ventajas:** precisiÃ³n, estabilidad y adaptabilidad a datos heterogÃ©neos.  
- **Desventajas:** menor interpretabilidad que modelos lineales.  
- **Siguiente paso:** integrar tÃ©cnicas de *feature importance* o *SHAP values* para explicar las predicciones mÃ©dicas.

---

## ğŸ“š Evidencias

- ğŸ““ CÃ³digo ejecutado en [Google Colab](https://colab.research.google.com/drive/1j-73Fk4EGqh3jqxff3nEj87ni_8ZEOxi?usp=sharing). 
- ğŸ“ GrÃ¡ficos en `docs/assets/diabetes_*`  
- ğŸ“˜ Dataset: *Diabetes Dataset (scikit-learn)*

---

## âœ¨ ReflexiÃ³n Personal

Esta prÃ¡ctica me permitiÃ³ fortalecer la comprensiÃ³n de la **validaciÃ³n cruzada como herramienta de evaluaciÃ³n objetiva** y la **comparaciÃ³n entre modelos lineales y no lineales**.  
TambiÃ©n comprendÃ­ la importancia de **comunicar resultados con grÃ¡ficos claros**, mostrando no solo precisiÃ³n sino tambiÃ©n **estabilidad**.

> â€œEvaluar no es solo medir el rendimiento, sino entender la confiabilidad del modelo para el mundo real.â€ ğŸŒ

---
