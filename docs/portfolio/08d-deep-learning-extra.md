---
title: "ğŸ§  Trabajo Extra â€” PrÃ¡ctica 8D: Callbacks en MLPs"
date: 2025-10-14
---

# ğŸ§  Trabajo Extra â€” PrÃ¡ctica 8D  
**Control del Entrenamiento con Callbacks en Redes Neuronales Multicapa (MLP)**

---

## ğŸ¯ Objetivo

Explorar cÃ³mo los **callbacks** de Keras permiten mejorar, controlar y estabilizar el entrenamiento de una red neuronal.  
Estos mecanismos automatizan decisiones como detener entrenamiento, ajustar la tasa de aprendizaje y guardar los mejores modelos.

---

## âš™ï¸ ConfiguraciÃ³n del experimento

| ParÃ¡metro | Valor |
|------------|--------|
| Dataset | Fashion-MNIST |
| Modelo | MLP con 2 capas ocultas |
| Ã‰pocas mÃ¡ximas | 50 |
| Batch size | 128 |
| DivisiÃ³n | 90% entrenamiento / 10% validaciÃ³n |

---

## ğŸ§© Callbacks utilizados

| Callback | PropÃ³sito | HiperparÃ¡metros clave |
|-----------|------------|------------------------|
| **EarlyStopping** | Detiene el entrenamiento cuando no mejora la mÃ©trica monitoreada. | `monitor="val_loss"`, `patience=5`, `restore_best_weights=True` |
| **ReduceLROnPlateau** | Reduce el learning rate cuando la validaciÃ³n se estanca. | `factor=0.5`, `patience=3` |
| **ModelCheckpoint** | Guarda el mejor modelo segÃºn val_accuracy. | `save_best_only=True` |
| **TensorBoard** | Permite visualizar mÃ©tricas, histogramas y comparaciones. | `log_dir="logs/callbacks"` |
| **LearningRateScheduler** | Modifica dinÃ¡micamente el LR segÃºn una funciÃ³n coseno. | `lr=1e-3 * (0.5 * (1 + cos(Ï€Â·epoch/10)))` |

---

## ğŸ§  Arquitectura del modelo

**Estructura del MLP:**  
- Capa de entrada â†’ 784 neuronas (28Ã—28)  
- Capa oculta 1 â†’ 256 neuronas (ReLU) + Dropout(0.3)  
- Capa oculta 2 â†’ 128 neuronas (ReLU)  
- Capa de salida â†’ 10 neuronas (Softmax)  

**Optimizador:** `Adam(lr=1e-3)`  
**FunciÃ³n de pÃ©rdida:** `sparse_categorical_crossentropy`  
**MÃ©trica:** `accuracy`

---

## ğŸ“Š Resultados del entrenamiento

El entrenamiento fue monitoreado con los callbacks activados.  
Se observÃ³ el siguiente comportamiento:

### ğŸ”¹ Accuracy
![accuracy_callbacks](../assets/ty1.png)

- EarlyStopping detuvo el entrenamiento en la **Ã©poca 18**, evitando sobreajuste.  
- ReduceLROnPlateau redujo el learning rate despuÃ©s de la Ã©poca 12, ayudando a mejorar la convergencia.  

### ğŸ”¹ PÃ©rdida (Loss)
![loss_callbacks](../assets/ty2.png)

- El modelo evitÃ³ el crecimiento del *val_loss*, mostrando que EarlyStopping fue efectivo.  
- Dropout y la reducciÃ³n progresiva de LR ayudaron a suavizar las curvas.  

### ğŸ”¹ EvoluciÃ³n del Learning Rate
![lr_schedule](../assets/ty3.png)

- Se aplicÃ³ un **patrÃ³n coseno decreciente**, Ãºtil para refinar los Ãºltimos pasos del entrenamiento.

---

## ğŸ§¾ EvaluaciÃ³n Final

| MÃ©trica | Valor |
|----------|--------|
| **Accuracy en test** | 0.889 |
| **Ã‰pocas utilizadas** | 18 (de 50 posibles) |
| **Learning rate final** | 0.00031 |

ğŸ† El modelo guardado por **ModelCheckpoint** (`best_model.keras`) logrÃ³ el mejor balance entre precisiÃ³n y estabilidad.

---

## ğŸ§  AnÃ¡lisis Detallado

### ğŸ”¸ EarlyStopping
- Previene overfitting al detener el entrenamiento al no mejorar la mÃ©trica.  
- Ideal cuando se desconoce el nÃºmero Ã³ptimo de Ã©pocas.  

### ğŸ”¸ ReduceLROnPlateau
- Disminuye el learning rate automÃ¡ticamente al estancarse la validaciÃ³n.  
- Permite que el modelo â€œrecupereâ€ capacidad de aprendizaje sin reiniciar el entrenamiento.

### ğŸ”¸ ModelCheckpoint
- Garantiza reproducibilidad y eficiencia: siempre se conserva la mejor versiÃ³n del modelo.  

### ğŸ”¸ TensorBoard
- Facilita comparar *runs*, analizar histogramas y observar el comportamiento del LR y gradientes.  

### ğŸ”¸ LearningRateScheduler
- Control total del decaimiento del LR.  
- La funciÃ³n coseno usada aquÃ­ genera un **descenso suave y progresivo**, ideal para ajustes finos.

---

## ğŸ“ˆ Conclusiones comparativas

| Aspecto | Sin Callbacks | Con Callbacks |
|----------|---------------|----------------|
| DuraciÃ³n del entrenamiento | 50 Ã©pocas fijas | ~18 Ã©pocas (EarlyStopping) |
| Overfitting | Alto | Reducido significativamente |
| Convergencia del LR | Constante | Adaptativa (ReduceLROnPlateau + Scheduler) |
| Rendimiento final | 0.86 | **0.889** |

---

## ğŸ’¬ ReflexiÃ³n Personal

> â€œEl uso de callbacks transforma el entrenamiento de un proceso manual en uno inteligente y adaptable.â€

- **EarlyStopping** y **ModelCheckpoint** fueron los mÃ¡s determinantes: evitan pÃ©rdida de tiempo y overfitting.  
- **ReduceLROnPlateau** ofrece un aprendizaje dinÃ¡mico y controlado.  
- Las visualizaciones ayudaron a interpretar cÃ³mo cada callback interviene en el aprendizaje.  
- AprendÃ­ la importancia de automatizar decisiones clave para un entrenamiento reproducible y eficiente.

---



## ğŸ“š Evidencias y Recursos

- [![Abrir en Colab](https://colab.research.google.com/drive/1DUsE45Gw0DhzdKEzig4il08V2M3r2Ykb?usp=sharing) â€” Notebook completo en Google Colab.


---

## ğŸ§¾ Datos TÃ©cnicos

- **Notebook:** `Practica8D_Callbacks_MLP.ipynb`  
- **Framework:** TensorFlow / Keras  
- **DuraciÃ³n:** ~25 min (GPU Colab)  
- **Autor:** Keyvi Alexander GarcÃ­a Linares  
- **Curso:** Machine Learning â€” UT2: Deep Learning Foundations  
- **Tipo:** Trabajo Extra â€” Callbacks y entrenamiento avanzado  

---

ğŸ“ **UbicaciÃ³n sugerida:**  
`docs/portfolio/08d-Callbacks-MLP.md`
