---
title: "PrÃ¡ctica 11 â€” YOLOv8 Fine-Tuning & Object Tracking"
date: 2025-01-01
---

# ğŸ§  PrÃ¡ctica 11 â€” YOLOv8 Fine-Tuning & Tracking

## ğŸ¯ Objetivo

Entrenar, evaluar y analizar un modelo **YOLOv8** mediante *fine-tuning* sobre un dataset de **frutas**, midiendo su desempeÃ±o en detecciÃ³n de objetos, y extendiendo el experimento hacia **seguimiento en video (tracking)** con **Norfair**.

---

## ğŸ“¦ Paso 1 â€” ConfiguraciÃ³n inicial y dependencias

```python
!pip install ultralytics norfair opencv-python tqdm
```

> Se utilizÃ³ **Google Colab con GPU T4** para acelerar el entrenamiento y el procesamiento de video.  
> Las librerÃ­as instaladas permiten realizar detecciÃ³n, tracking y visualizaciÃ³n avanzada en tiempo real.

---

## ğŸ Paso 2 â€” Dataset y preparaciÃ³n

Dataset: **Fruits Detection Dataset**  
Contiene imÃ¡genes con **manzanas, bananas, y naranjas** en diferentes condiciones de luz y fondo.  

ğŸ“‚ Estructura:
```
datasets/
 â”œâ”€â”€ train/images/
 â”œâ”€â”€ train/labels/
 â”œâ”€â”€ val/images/
 â””â”€â”€ val/labels/
```

ğŸ“¸ **DISTRIBUCIÃ“N DE CLASES (TRAIN)**
![dataset-fruits](../assets/yolo01.png)

**Observaciones:**
- IluminaciÃ³n y Ã¡ngulos variados.
- TamaÃ±os heterogÃ©neos de los objetos.
- Algunas imÃ¡genes con oclusiÃ³n parcial.
**ğŸ¤” Preguntas sobre DistribuciÃ³n del Dataset:**

**Â¿Las clases estÃ¡n balanceadas? Â¿QuÃ© problemas podrÃ­a causar un desbalance?**
- No, el dataset muestra cierto desbalance entre clases. Algunas frutas o productos tienen muchas mÃ¡s instancias que otras,Un desbalance puede hacer que el modelo aprenda mejor las clases mÃ¡s frecuentes y falle al reconocer las menos representadas.

**Â¿QuÃ© clase tiene mÃ¡s instancias? Â¿Crees que el modelo serÃ¡ mejor detectando esa clase?**
- La clase con mÃ¡s instancias â€”por ejemplo, apple o bananaâ€” probablemente serÃ¡ la mejor detectada, porque el modelo tiene mÃ¡s ejemplos para aprender sus caracterÃ­sticas visuales.

**Â¿La clase con menos instancias podrÃ­a tener mÃ¡s errores? Â¿Por quÃ©?**
- SÃ­, las clases con menos ejemplos tienden a tener mÃ¡s errores porque el modelo no ve suficientes variaciones durante el entrenamiento.

**Si tuvieras que agregar mÃ¡s datos, Â¿quÃ© clase priorizarÃ­as y por quÃ©?**
- PriorizarÃ­a las clases con menor cantidad de instancias para equilibrar el dataset. Aumentar su presencia ayudarÃ­a al modelo a aprender de forma mÃ¡s equitativa
---
ğŸ“¸ **DISTRIBUCIÃ“N DE CLASES (TRAIN)Visualizar Ejemplos del Dataset**
![dataset-](../assets/yolo02.png)
---
## âš™ï¸ Paso 3 â€” Entrenamiento YOLOv8 (Fine-tuning)

```python
from ultralytics import YOLO

model = YOLO("yolov8n.pt")  # Modelo base preentrenado
model.train(data="fruits.yaml", epochs=30, imgsz=640, batch=16)
```

ğŸ“ˆ **Entrenamiento:**
- Base: `YOLOv8n` (Nano, rÃ¡pido para prototipado)
- Ã‰pocas: 30  
- TamaÃ±o de imagen: 640x640  
- Optimizador: AdamW  
- PÃ©rdida: `bbox + cls + dfl`

ğŸ“Š **Curvas de entrenamiento:**
![training-curves](../assets/yolo03.png)

**InterpretaciÃ³n:**
- La pÃ©rdida total desciende de forma constante durante las primeras 20 Ã©pocas.  
- Las mÃ©tricas de validaciÃ³n (`mAP50` y `mAP50-95`) se estabilizan hacia el final, indicando convergencia.

---

## ğŸ§ª Paso 4 â€” EvaluaciÃ³n del modelo

```python
results = model.val()
results.box.map50, results.box.map
```

ğŸ“ˆ **Resultados obtenidos:**
| MÃ©trica | Valor |
|----------|--------|
| mAP@50 | 0.926 |
| mAP@50â€“95 | 0.704 |
| Precision | 0.911 |
| Recall | 0.887 |



**InterpretaciÃ³n:**
- Excelente precisiÃ³n y recall (>0.88).  
- Las confusiones ocurren principalmente entre **banana** y **mango**, debido a color y forma similares.

---

## ğŸ” Paso 5 â€” ComparaciÃ³n: Modelo base vs Fine-tuned

Se comparÃ³ el desempeÃ±o del modelo **preentrenado YOLOv8n** (sin fine-tuning) frente al modelo **entrenado con dataset de frutas**.

ğŸ“· **Resultados comparativos:**
![base-vs-finetuned](../assets/yolo04.png)

| Modelo | mAP@50 | Tiempo de inferencia | ObservaciÃ³n |
|---------|--------|----------------------|--------------|
| Base YOLOv8n | 0.64 | 8.1 ms | No especializado, confunde clases. |
| Fine-tuned | 0.92 | 9.3 ms | Reconoce con precisiÃ³n frutas y lÃ­mites. |

**ConclusiÃ³n:**  
El fine-tuning adaptÃ³ el modelo a las condiciones especÃ­ficas del dataset (iluminaciÃ³n, forma y textura de frutas), logrando una mejora de **+28% en mAP**.

---

## ğŸ§  Paso 6 â€” VisualizaciÃ³n de predicciones

```python
results = model.predict(source="datasets/val/images", conf=0.5)
```

ğŸ“¸ **Ejemplos:**
![predictions](../assets/yolo05.png)

**InterpretaciÃ³n visual:**
- Las cajas delimitadoras son precisas y ajustadas.  
- Las etiquetas y scores son consistentes.  
- Buen manejo de mÃºltiples objetos por imagen.

---

## ğŸï¸ Paso 7 â€” Seguimiento de objetos (Tracking)

Se integrÃ³ el modelo entrenado con **Norfair** para realizar seguimiento en video.

```python
from norfair import Detection, Tracker
```

### ğŸ§© Proceso:
1. Se procesan frames del video con YOLOv8.  
2. Cada detecciÃ³n se transforma en `Detection()` con su bounding box y score.  
3. Norfair mantiene la identidad del objeto entre frames.  

ğŸ“¹ **Ejemplo de tracking:**  
![Video de tracking](../assets/videofl.gif)


ğŸ“Š **VisualizaciÃ³n:**
- Colores Ãºnicos por objeto.
- Trayectorias suaves y persistentes.
- IDs consistentes incluso ante oclusiones parciales.

---



## ğŸš¦ Paso 10 â€” ExportaciÃ³n y uso prÃ¡ctico

```python
model.export(format="onnx")
```

- El modelo fue exportado en formato **ONNX** para despliegue en apps mÃ³viles o edge.  
- Compatible con TensorRT y OpenVINO para inferencia acelerada.

ğŸ“¦ **Archivos generados:**
| Archivo | DescripciÃ³n |
|----------|-------------|
| `yolov8n_fruit.pt` | Modelo fine-tuned |
| `yolov8n_fruit.onnx` | VersiÃ³n optimizada para inferencia |
| `fruits.yaml` | ConfiguraciÃ³n del dataset |

---

## ğŸ’¬ ReflexiÃ³n personal

> â€œEsta prÃ¡ctica me permitiÃ³ experimentar con un pipeline completo de visiÃ³n por computador:  
> desde *fine-tuning* con YOLOv8 hasta *tracking* en video con Norfair.  
> ComprendÃ­ la importancia del balance entre precisiÃ³n, velocidad e interpretabilidad en tareas de visiÃ³n aplicadas a entornos reales.â€

---

## ğŸš€ Conclusiones generales

1. **YOLOv8** ofrece una excelente relaciÃ³n entre velocidad y precisiÃ³n.  
2. El **fine-tuning** mejora drÃ¡sticamente el rendimiento en datasets especÃ­ficos.  
3. **Norfair** permite un seguimiento fluido con pocos recursos.  
4. El enfoque combina **detecciÃ³n + tracking + explicabilidad**, acercÃ¡ndose a soluciones industriales completas.

---

## ğŸ“š Evidencias y archivos

- ğŸ““ Notebook ejecutado: [![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/10BoaiubP6ico1UmviDkHg95ZxdgUQUa1?usp=sharing)
- ğŸ“· ImÃ¡genes incluidas:
  - Dataset y ejemplos de entrenamiento  
  - Curvas de aprendizaje  
  - ComparaciÃ³n base vs fine-tuned  
  - Tracking y Grad-CAM  
- ğŸ’¾ Archivos: `yolov8n_fruit.pt`, `fruits.yaml`, `tracking_video.mp4`

---

## ğŸ“˜ Referencias

- [Ultralytics YOLOv8 Docs](https://docs.ultralytics.com)  
- [Norfair Tracking Library](https://tryolabs.github.io/norfair/)  
- [Grad-CAM Paper (Selvaraju et al., 2017)](https://arxiv.org/abs/1610.02391)  
- [Object Detection Datasets â€” Kaggle](https://www.kaggle.com/datasets)

---
