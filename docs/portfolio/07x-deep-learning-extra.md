---
title: "ğŸ§  PrÃ¡ctica 7 (Extra) â€” Redes Neuronales en Diferentes Datasets"
date: 2025-09-22
---

# ğŸ§  PrÃ¡ctica 7 (Extra) â€” Redes Neuronales en Diferentes Datasets  
**Unidad TemÃ¡tica 2 â€” Deep Learning Foundations**

---

## ğŸ“˜ Contexto General

Este trabajo complementa la prÃ¡ctica anterior (â€œDe PerceptrÃ³n a Redes Neuronalesâ€) extendiendo los experimentos a **diferentes tipos de datasets**, con el objetivo de observar cÃ³mo **cambia el desempeÃ±o y la frontera de decisiÃ³n** entre un **PerceptrÃ³n simple** y un **MLP (Multilayer Perceptron)**.

Se analizan **tres tipos de problemas**:
- ClasificaciÃ³n **binaria** (cÃ­rculos y medias lunas).  
- ClasificaciÃ³n **multiclase** (dÃ­gitos y vino).  
- **RegresiÃ³n continua** (California Housing).  

---

## ğŸ¯ Objetivos

- Comparar el rendimiento del **PerceptrÃ³n** y el **MLP** en distintos contextos.  
- Visualizar las **fronteras de decisiÃ³n** en datasets lineales y no lineales.  
- Evaluar la capacidad del MLP para **generalizar** mÃ¡s allÃ¡ de problemas simples.  
- Reflexionar sobre cÃ³mo cambia el comportamiento del modelo segÃºn el tipo de tarea.

---

## âš™ï¸ MetodologÃ­a

1. Se seleccionaron datasets sintÃ©ticos y reales de `scikit-learn`.  
2. Se aplicaron dos modelos por dataset:
   - **PerceptrÃ³n simple:** modelo lineal base.  
   - **MLPClassifier / MLPRegressor:** red neuronal con capas ocultas.  
3. Los datos se escalaron con `StandardScaler` y se dividieron en entrenamiento/prueba (80/20).  
4. Se registraron mÃ©tricas, grÃ¡ficas y comparaciones interpretativas.

---

## ğŸ”µ 1ï¸âƒ£ CÃ­rculos concÃ©ntricos â€” *make_circles()*


**AnÃ¡lisis del dataset:**  
Los datos representan dos clases en forma de anillos concÃ©ntricos. Este patrÃ³n es **no lineal**, por lo que el perceptrÃ³n fallarÃ¡ al trazar una sola frontera de separaciÃ³n.

### ğŸ”¹ Resultados
| Modelo | PrecisiÃ³n |
|---------|------------|
| PerceptrÃ³n | 0.52 |
| MLP (1 capa oculta de 8) | 0.96 |

**VisualizaciÃ³n de fronteras:**
- PerceptrÃ³n: ![PerceptrÃ³n - Circles](../assets/pi1.png)  
- MLP: ![MLP - Circles](../assets/pi2.png)

**InterpretaciÃ³n:**  
El **PerceptrÃ³n** dibuja una lÃ­nea recta que corta el conjunto sin sentido geomÃ©trico.  
El **MLP**, en cambio, genera una frontera **circular** que se ajusta al patrÃ³n de los datos, mostrando que puede aprender **relaciones no lineales**.

---

## ğŸŒ™ 2ï¸âƒ£ Medias Lunas â€” *make_moons()*



**DescripciÃ³n:**  
Las medias lunas son un clÃ¡sico ejemplo de **distribuciÃ³n no lineal**, muy Ãºtil para visualizar el poder del MLP.

### ğŸ”¹ Resultados
| Modelo | PrecisiÃ³n |
|---------|------------|
| PerceptrÃ³n | 0.78 |
| MLP (10 neuronas ocultas) | 0.98 |

**VisualizaciÃ³n:**
- PerceptrÃ³n: ![PerceptrÃ³n - Moons](../assets/pi3.png)  
- MLP: ![MLP - Moons](../assets/pi4.png)

**InterpretaciÃ³n:**  
El **MLP** logra una separaciÃ³n **curva y precisa**, mientras que el perceptrÃ³n deja amplias zonas mal clasificadas.  
Esto demuestra cÃ³mo las **activaciones no lineales (ReLU)** permiten al modelo â€œdoblarâ€ el espacio de decisiÃ³n.

---

## ğŸ”¢ 3ï¸âƒ£ DÃ­gitos Manuscritos â€” *load_digits()*

![Digits sample](../assets/pi5.png)

**DescripciÃ³n:**  
Dataset de 1797 imÃ¡genes (8Ã—8 pÃ­xeles) de nÃºmeros escritos a mano (0â€“9).  
Cada muestra es una matriz de intensidades de gris.

### ğŸ”¹ Resultados del MLP

| MÃ©trica | Valor |
|----------|-------|
| PrecisiÃ³n | 0.96 |
| Capas ocultas | (64,) |
| ActivaciÃ³n | ReLU |



**InterpretaciÃ³n:**  
El MLP logra **alta precisiÃ³n multiclase**, diferenciando patrones numÃ©ricos complejos.  
La representaciÃ³n en capas ocultas actÃºa como un **extractor automÃ¡tico de caracterÃ­sticas**, sustituyendo el preprocesamiento manual.

---

## ğŸ· 4ï¸âƒ£ ClasificaciÃ³n de Vinos â€” *load_wine()*

![Wine PCA](../assets/pi6.png)

**DescripciÃ³n:**  
Dataset quÃ­mico con 13 atributos (Ã¡cidos, alcohol, fenoles, color, etc.) que clasifican vinos en **3 categorÃ­as**.

### ğŸ”¹ Resultados
| MÃ©trica | Valor |
|----------|-------|
| Accuracy | 0.98 |
| Capas ocultas | (16, 8) |
| ActivaciÃ³n | ReLU |


**InterpretaciÃ³n:**  
El modelo logra una **clasificaciÃ³n casi perfecta**.  
Esto evidencia cÃ³mo el MLP maneja correctamente **datasets multiclase tabulares**, adaptando los pesos segÃºn la complejidad de las variables.

---

## ğŸ—ï¸ 5ï¸âƒ£ ClasificaciÃ³n MÃ©dica â€” *CÃ¡ncer de Mama*

![Breast Cancer chart](../assets/pi7.png)

**DescripciÃ³n:**  
Dataset clÃ­nico con caracterÃ­sticas de cÃ©lulas mamarias.  
El objetivo es clasificar entre **benigno y maligno**.

### ğŸ”¹ Resultados
| Modelo | PrecisiÃ³n |
|---------|------------|
| MLP (30Ã—15 neuronas) | 0.99 |



**InterpretaciÃ³n:**  
La red neuronal detecta patrones mÃ©dicos con altÃ­sima precisiÃ³n.  
El MLP demuestra **gran capacidad de generalizaciÃ³n**, convirtiÃ©ndose en una herramienta clave en diagnÃ³stico asistido por IA.

---

## ğŸ  6ï¸âƒ£ RegresiÃ³n â€” *California Housing*

![Housing Regression](../assets/pi8.png)

**DescripciÃ³n:**  
Dataset real con informaciÃ³n socioeconÃ³mica de California.  
Tarea: predecir el **valor medio de la vivienda**.

### ğŸ”¹ Resultados
| MÃ©trica | Valor |
|----------|-------|
| RMSE | 0.49 |
| Capas ocultas | (64, 32) |

**InterpretaciÃ³n:**  
El modelo logra una relaciÃ³n casi lineal entre predicciones y valores reales.  
Demuestra que el MLP tambiÃ©n puede manejar **problemas de regresiÃ³n continua**, aunque con mÃ¡s sensibilidad a hiperparÃ¡metros.

---

## âš–ï¸ Comparativa Global

| Dataset | Tipo | Mejor Modelo | PrecisiÃ³n / RMSE | ObservaciÃ³n |
|----------|------|---------------|------------------|--------------|
| CÃ­rculos | Binario | MLP | 0.96 | No lineal, patrÃ³n circular. |
| Lunas | Binario | MLP | 0.98 | Frontera curva y estable. |
| DÃ­gitos | Multiclase | MLP | 0.96 | Extrae representaciones visuales. |
| Vino | Multiclase | MLP | 0.98 | Muy buena generalizaciÃ³n. |
| CÃ¡ncer | Binario | MLP | 0.99 | Alta precisiÃ³n mÃ©dica. |
| Housing | RegresiÃ³n | MLP | RMSE = 0.49 | Buen ajuste, requiere tuning. |

---

## ğŸ’¬ InterpretaciÃ³n Global

**Conclusiones:**
- El **PerceptrÃ³n** solo funciona en escenarios lineales simples.  
- El **MLP** aprende patrones complejos, incluso con ruido o relaciones no triviales.  
- Las **funciones de activaciÃ³n no lineales** son el factor clave que permite flexibilidad y generalizaciÃ³n.  
- La arquitectura y la normalizaciÃ³n influyen directamente en la estabilidad del entrenamiento.

> ğŸ§© En resumen: el MLP "dobla" el espacio de entrada hasta hacerlo separable, tanto en clasificaciÃ³n como en regresiÃ³n.

---

## ğŸ¤” Preguntas de ReflexiÃ³n

**Â¿QuÃ© observaste en comÃºn entre los datasets no lineales?**  
Que todos requieren **mÃ¡s de una frontera** para separarse correctamente. Los modelos lineales no bastan.

**Â¿Por quÃ© el MLP logra mejores resultados?**  
Porque introduce **capas ocultas y activaciones**, permitiendo combinar mÃºltiples hiperplanos y aprender transformaciones complejas.

**Â¿QuÃ© pasa si se usan demasiadas capas?**  
El modelo puede **sobreajustar** los datos y perder capacidad de generalizaciÃ³n.

**Â¿QuÃ© tipo de problemas se benefician mÃ¡s de un MLP?**  
Problemas con **patrones no lineales, multiclase o ruidosos**, donde un modelo lineal no puede encontrar relaciones claras.

---

## ğŸ§© PrÃ³ximos pasos

- Experimentar con **mÃ¡s funciones de activaciÃ³n** (`tanh`, `elu`).  
- Evaluar el uso de **Dropout** y **Batch Normalization**.  
- Aplicar **tuning de hiperparÃ¡metros** (GridSearchCV o RandomizedSearchCV).  
- Implementar versiones del modelo en **PyTorch o TensorFlow** para comparar desempeÃ±o.

---

ğŸ“„ **Notebook original:** `Practica7_Extra_MLP_Datasets.ipynb`  
ğŸ§© **Tipo de prÃ¡ctica:** Experimental â€” Redes Neuronales y GeneralizaciÃ³n  
ğŸ“ **UbicaciÃ³n sugerida:** `docs/portfolio/07x-MLP-Datasets.md`

---
