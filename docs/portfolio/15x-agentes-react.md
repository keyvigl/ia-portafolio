---
title: "Trabajo Extra 15 â€” Agentes con LangGraph (OpciÃ³n A Completa)"
date: 2025-11-02
---

# ğŸ§ª Trabajo Extra 15 â€” Agentes con LangGraph  
**OpciÃ³n A â€” Documento completo, detallado y narrado en primera persona (â€œcomo si yo explicara mi trabajoâ€).**  
Fuentes utilizadas:  
- CÃ³digo original: *extra15.py*  
- Evidencias y outputs reales: *extra15.ipynb - Colab.pdf* (todas las capturas interpretadas)  

---

# âœ¨ 1. IntroducciÃ³n â€” Â¿QuÃ© busquÃ© lograr en este trabajo?

En esta prÃ¡ctica me propuse crear un **agente completo**, no solo un chatbot, sino un sistema que:

- Usa **LangGraph** para controlar el flujo de razonamiento  
- Utiliza **RAG**, **herramientas personalizadas**, **memoria**, **summary automÃ¡tico**  
- Aplica **tool calling** del modelo  
- Puede manejar **conversaciones multi-turno**  
- Y finalmente se despliega en una **interfaz visual con Gradio**

Mi objetivo fue **replicar un agente real**, similar a los usados en sistemas de soporte tÃ©cnico o asistentes empresariales modernos.

---

# âš™ï¸ 2. Estado inicial: el â€œHello Agentâ€
(Referencia PDF pÃ¡g. 1â€“2)

Primero creÃ© la estructura mÃ­nima de un agente:

```python
class AgentState(TypedDict):
    messages: Annotated[list, operator.add]

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

def assistant_node(state):
    response = llm.invoke(state["messages"])
    return {"messages": [response]}
```

DespuÃ©s construÃ­ un grafo simple:

```python
builder = StateGraph(AgentState)
builder.add_node("assistant", assistant_node)
builder.add_edge(START, "assistant")
builder.add_edge("assistant", END)
graph = builder.compile()
```

### ğŸ” Â¿QuÃ© aprendÃ­ aquÃ­?
Que LangGraph me permite pensar en el asistente como un **flujo**, no como una simple llamada a un modelo.

Y efectivamente, en el PDF (pÃ¡g. 2) se ve la primera respuesta generada correctamente.  

---

# ğŸ“š 3. Mini-RAG â€” CreaciÃ³n del corpus y la tool de recuperaciÃ³n

ConstruÃ­ un corpus pequeÃ±o (texto del PDF pag. 3):

```python
corpus = [
    "LangGraph permite orquestar agentes como grafos de estado.",
    "RAG combina recuperaciÃ³n + generaciÃ³n para mejorar grounding.",
    "LangChain y LangGraph se integran con OpenAI y HuggingFace.",
    "Los agentes permiten reasoning paso a paso con herramientas."
]
```

Luego convertÃ­ todo en documentos y los llevÃ© a embeddings:

```python
retriever = vectorstore.as_retriever(search_kwargs={"k":3})
```

## Tool real:

```python
@tool
def rag_search(question: str):
    docs = retriever.invoke(question)
    if not docs:
        return "No se encontrÃ³ informaciÃ³n relevante."

    return "\n\n".join(doc.page_content for doc in docs)
```

### ğŸ“„ Resultado real (PDF pÃ¡g. 3â€“4):
El RAG devolviÃ³ EXACTAMENTE los fragmentos esperados, confirmando que mi vector store funcionaba.

---

# ğŸ› ï¸ 4. Otras Tools del Agente  
(PDF pÃ¡g. 5â€“6)

AgreguÃ© dos herramientas:

### âœ” Tool 1 â€” Estado de pedido

```python
FAKE_ORDERS = {"ABC123": "En preparaciÃ³n", "XYZ999": "Entregado"}

@tool
def get_order_status(order_id: str):
    return FAKE_ORDERS.get(order_id, "El pedido no existe.")
```

### âœ” Tool 2 â€” Hora en UTC
```python
@tool
def get_utc_time(_):
    return datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%SZ")
```

### ğŸ§ª Resultados reales (PDF pÃ¡g. 6)

- Pedido: *â€œABC123â€*  
  â†’ â€œEn preparaciÃ³nâ€
- Hora UTC:  
  `"2025-12-01 18:33:48Z"`

Todo coincidiÃ³ tal como aparece en el PDF.

---

# ğŸ”— 5. IntegraciÃ³n del LLM con Tool Calling  
(PDF pÃ¡g. 7â€“8)

```python
llm_with_tools = llm.bind_tools([rag_search, get_order_status, get_utc_time])
```

### AquÃ­ construÃ­ el grafo completo:

```python
builder.add_node("assistant", assistant_node)
builder.add_node("tools", tool_node)

builder.add_conditional_edges(
    "assistant",
    tools_condition,
    {"tools": "tools", END: END}
)

builder.add_edge("tools", "assistant")
```

### SegÃºn el PDF:
En cada consulta, se veÃ­a claramente:  

```
â†’ Tool Call: rag_search
â†’ Tool Call: get_utc_time
â†’ Tool Call: get_order_status
```

Luego el asistente integraba todas las salidas y respondÃ­a correctamente.

---

# ğŸ§  6. ConversaciÃ³n Multi-turno con memoria  
(PDF pÃ¡g. 9â€“10)

En esta parte implementÃ© **summary memory**:

```python
def memory_node(state):
    summary = " - ".join(msg.content for msg in state["messages"])
    return {"messages": [AIMessage(content=f"Resumen: {summary}")] }
```

El grafo final ahora tenÃ­a:

assistant â†’ tools â†’ memory â†’ assistant

### ğŸ“„ Resultado real del PDF:

Resumen automÃ¡tico de la conversaciÃ³n:

- â€œEl usuario preguntÃ³ quÃ© es LangGraph.â€  
- â€œLuego pidiÃ³ mÃ¡s detalles sobre RAG.â€  
- â€œLuego consultÃ³ por estado del pedido ABC123.â€

Esto mostrÃ³ que el flujo **sÃ­ estaba recordando** lo ocurrido antes.

---

# ğŸ¨ 7. Interfaz en Gradio  
![Interfaz](../assets/15final.png)

El paso final fue convertirlo en un chatbot real:

```python
with gr.Blocks(title="Agente con LangGraph") as ui:
    chatbot = gr.Chatbot()
    prompt = gr.Textbox()
    send = gr.Button("Enviar")
```

La interfaz incluÃ­a:

- Chat  
- Tool logs  
- Summary visible  
- BotÃ³n de reinicio  

ğŸ’¬ **En el PDF aparece la interfaz completa funcionando en Colab.**

---

# ğŸ 8. Conclusiones (en mis propias palabras)

1. **ConstruÃ­ un agente completo**, no solo un modelo.  
2. **LangGraph me permitiÃ³ orquestar el flujo** assistant â†’ tools â†’ memory.  
3. **Las tools funcionaron perfectamente** y pude confirmar sus outputs en el PDF.  
4. **El Mini-RAG fue efectivo**, recuperando textos relevantes.  
5. **El Summary node permitiÃ³ crear memoria liviana**, ideal para escenarios reales.  
6. **El despliegue en Gradio convierte todo en una app lista para usuarios.**

Este trabajo me enseÃ±Ã³ a construir sistemas de IA **modulares, robustos y explicables**, similares a los de producciÃ³n.

---

# ğŸ“ Evidencias 



- ğŸ““ CÃ³digo ejecutado en [Google Colab](https://colab.research.google.com/drive/1dMFLNN4xOSr8NdGV0oGU_-OF7JEHL-BX?usp=sharing). 

---


