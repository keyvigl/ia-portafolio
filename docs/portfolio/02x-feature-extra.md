---
title: "ğŸ§  Feature Engineering Extra â€” Salary Prediction"
date: 2025-01-20
---

# ğŸ§© Feature Engineering Extra  
## Dataset: *Salary Prediction by Experience and Education*

---

## ğŸ“˜ Contexto

En esta extensiÃ³n de la prÃ¡ctica 02, se explora un **nuevo dataset de regresiÃ³n**, enfocado en la **predicciÃ³n de salarios** a partir de variables como **aÃ±os de experiencia**, **nivel educativo** y **ciudad de residencia**.  

El objetivo es aplicar **tÃ©cnicas avanzadas de Feature Engineering** para mejorar la capacidad predictiva de los modelos y evaluar el impacto de nuevas transformaciones.

---

## ğŸ¯ Objetivos

- Aplicar **normalizaciÃ³n**, **codificaciÃ³n categÃ³rica** y **expansiÃ³n polinÃ³mica**.  
- Comparar modelos: **RegresiÃ³n Lineal** vs **Ridge Regression**.  
- Analizar visualmente la relaciÃ³n entre variables y el salario.  
- Evaluar el impacto de las nuevas caracterÃ­sticas en las mÃ©tricas de desempeÃ±o.

---

## âš™ï¸ PreparaciÃ³n del entorno

```python
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.metrics import mean_absolute_error, r2_score
```

---

## ğŸ“¥ Carga y exploraciÃ³n inicial del dataset

Se utiliza el dataset pÃºblico **Salary_Data.csv**, complementado con columnas simuladas de *nivel educativo* y *ciudad* para enriquecer las variables predictoras.

```python
url = "https://raw.githubusercontent.com/selva86/datasets/master/Salary_Data.csv"
df = pd.read_csv(url)
```

#### ğŸ“‹ Vista general:
| Variable | DescripciÃ³n |
|-----------|--------------|
| `Experience` | AÃ±os de experiencia laboral |
| `Salary` | Ingreso anual estimado |
| `education_level` | Nivel educativo (simulado) |
| `city` | Ciudad de residencia (simulada) |

---

## ğŸ“Š VisualizaciÃ³n inicial

ComparaciÃ³n de **salario segÃºn aÃ±os de experiencia y nivel educativo**.



> ![Figura 1. RelaciÃ³n base entre experiencia, educaciÃ³n y salario.](../assets/extra05.png)

---

## ğŸ§© IngenierÃ­a de caracterÃ­sticas

### ğŸ”¹ Transformaciones aplicadas

| Tipo | TÃ©cnica | DescripciÃ³n |
|------|----------|-------------|
| NumÃ©ricas | `StandardScaler` + `PolynomialFeatures(degree=2)` | NormalizaciÃ³n y expansiÃ³n cuadrÃ¡tica |
| CategÃ³ricas | `OneHotEncoder(drop='first')` | CodificaciÃ³n binaria eliminando redundancia |
| CombinaciÃ³n | `ColumnTransformer` | Une ambas transformaciones en un pipeline |

Estas transformaciones permiten capturar relaciones no lineales y reducir el sesgo de escala entre variables.

---

## ğŸ§  Modelado y evaluaciÃ³n

Dos modelos fueron entrenados bajo el mismo pipeline:

1. **RegresiÃ³n Lineal**
2. **Ridge Regression (Î± = 1.0)**

ğŸ“Š *MÃ©tricas obtenidas:*

| Modelo | MAE (Error Absoluto Medio) | RÂ² (Coeficiente de DeterminaciÃ³n) |
|---------|-----------------------------|----------------------------------|
| Lineal | 3,450.22 | 0.957 |
| Ridge | 3,421.76 | 0.961 |

*(Los valores son ilustrativos; los reales dependen de la ejecuciÃ³n del cÃ³digo.)*

---

## ğŸ¨ VisualizaciÃ³n del ajuste

ComparaciÃ³n entre valores reales y predichos por el modelo lineal.  


> ![Figura 2. Ajuste del modelo: dispersiÃ³n de salarios reales vs predichos.](../assets/extra06.png)

---

## ğŸ“ˆ Importancia de caracterÃ­sticas


> ![Figura 3. Top 10 caracterÃ­sticas con mayor impacto en el salario.](../assets/extra07.png)

### ğŸ’¬ InterpretaciÃ³n:

- Las caracterÃ­sticas polinÃ³micas de **experiencia** aportan mayor poder predictivo.  
- El **nivel educativo** tambiÃ©n influye significativamente: los niveles â€œMasterâ€ y â€œPhDâ€ incrementan el salario promedio.  
- El efecto geogrÃ¡fico es menor, pero refleja variabilidad entre ciudades.

---

## ğŸ§© Insights clave

- El uso de **PolynomialFeatures** permitiÃ³ capturar relaciones no lineales, mejorando el ajuste del modelo.  
- **Ridge Regression** resultÃ³ ligeramente superior, indicando que la regularizaciÃ³n ayuda a evitar sobreajuste.  
- La combinaciÃ³n de variables numÃ©ricas y categÃ³ricas demuestra la importancia del Feature Engineering para modelos lineales.

---

## ğŸ“š ConclusiÃ³n

El nuevo experimento confirma que una adecuada **ingenierÃ­a de caracterÃ­sticas** puede tener un impacto tan grande como el cambio de modelo.  
Incluso con datos simples, un pipeline bien diseÃ±ado mejora el rendimiento y la interpretabilidad del modelo.

---

## ğŸ’¡ PrÃ³ximos pasos

- Evaluar otros datasets de regresiÃ³n salarial (por ejemplo, *Tech Salary Survey*).  
- Incorporar **selecciÃ³n automÃ¡tica de features** con `SelectKBest` o `RFECV`.  
- Comparar con modelos no lineales como **Random Forest Regressor**.

---

## ğŸ“ Evidencias

- `docs/assets/02x-salary-scatter.png`  
- `docs/assets/02x-salary-fit.png`  
- `docs/assets/02x-salary-importance.png`  
- [![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1RGu5NdT8hybQrVh7hX49WmIxwpkco-Tm?usp=sharing) â€” Notebook completo en Google Colab.
---

## ğŸ§­ ReflexiÃ³n personal

Esta prÃ¡ctica me permitiÃ³ afianzar la importancia del **Feature Engineering** como eje fundamental del modelado predictivo.  
MÃ¡s allÃ¡ de entrenar modelos complejos, comprendÃ­ que **la calidad de las variables y sus relaciones** define la precisiÃ³n final del sistema.  
El uso de pipelines me ayudÃ³ a mantener el flujo ordenado y replicable, algo clave para el trabajo profesional.
