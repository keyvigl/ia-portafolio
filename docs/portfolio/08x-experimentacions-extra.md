---
title: "üìà Trabajo Extra ‚Äî Pr√°ctica 8: Experimentaci√≥n con MLP en Varios Datasets"
date: 2025-10-13
---

# üìà Trabajo Extra ‚Äî Pr√°ctica 8  
**Experimentaci√≥n de Redes Neuronales Multicapa (MLP) con MNIST, Fashion-MNIST y CIFAR-100**

---

## üéØ Contexto del Experimento

Esta pr√°ctica tiene como objetivo **extender el uso de MLP (Multi-Layer Perceptron)** aplicado en la Pr√°ctica 8 original a **nuevos datasets reales** de distinta complejidad.  
Se mantiene el mismo pipeline de trabajo ‚Äî *aplanar ‚Üí MLP ‚Üí entrenar* ‚Äî para observar c√≥mo var√≠a el rendimiento del modelo seg√∫n el tipo de datos.

---

## üß© Datasets Utilizados

| Dataset | Descripci√≥n | Tama√±o Imagen | N¬∫ Clases | Tipo |
|----------|-------------|----------------|------------|------|
| üßÆ **MNIST** | D√≠gitos manuscritos 0‚Äì9 | 28√ó28 (gris) | 10 | Clasificaci√≥n simple |
| üëï **Fashion-MNIST** | Prendas de vestir (ropa, zapatos, bolsos) | 28√ó28 (gris) | 10 | Clasificaci√≥n moderada |
| üåà **CIFAR-100** | Objetos naturales a color | 32√ó32√ó3 (RGB) | 100 | Clasificaci√≥n compleja |

Todos fueron cargados con `tf.keras.datasets`, lo que facilita la comparaci√≥n bajo las mismas condiciones de entrenamiento.

---

## ‚öôÔ∏è Pipeline de Entrenamiento

El flujo de trabajo general fue id√©ntico para los tres conjuntos:

```text
Cargar dataset ‚Üí Normalizar im√°genes ‚Üí Aplanar ‚Üí Construir MLP ‚Üí Entrenar ‚Üí Evaluar
```

### üîπ Arquitectura usada:
```text
Input ‚Üí Dense(256, relu) ‚Üí Dropout(0.3) ‚Üí Dense(128, relu) ‚Üí Dense(num_classes, softmax)
```

- **Optimizador:** Adam  
- **Funci√≥n de p√©rdida:** Sparse Categorical Crossentropy  
- **√âpocas:** 10  
- **Batch size:** 128  
- **Validaci√≥n:** 10% de los datos de entrenamiento

---

## üìä Resultados: MNIST ‚Äî D√≠gitos Manuscritos

![mnist_samples](../assets/qw1.png)

```text
MNIST ‚Äî Entrenamiento
loss: 0.0817 - accuracy: 0.9772 - val_accuracy: 0.9768
```

‚úÖ **Accuracy final:** 97.6%  
‚úÖ **P√©rdida final:** 0.081  

### üîç Interpretaci√≥n

- Las cifras est√°n bien delimitadas y centradas, lo cual permite al modelo aprender con facilidad.  
- El MLP logra **una separaci√≥n casi perfecta de clases** con solo dos capas densas.  
- No hay evidencia de *overfitting*, las curvas se mantienen estables.

![mnist_acc](../assets/qw2.png)

üß† *Insight:*  
El conjunto MNIST sigue siendo el punto de partida ideal para probar redes densas simples.

---

## üëö Resultados: Fashion-MNIST ‚Äî Clasificaci√≥n de Ropa

![fashion_samples](../assets/qw3.png)

```text
Fashion-MNIST ‚Äî Entrenamiento
loss: 0.3152 - accuracy: 0.8879 - val_accuracy: 0.8807
```

‚úÖ **Accuracy final:** 88.0%  
‚úÖ **P√©rdida final:** 0.31  

### üîç Interpretaci√≥n

- A pesar de ser im√°genes similares (grises 28√ó28), las diferencias entre prendas son m√°s sutiles.  
- El modelo **aumenta su dificultad** para separar clases con texturas y bordes parecidos.  
- Las clases m√°s confundidas fueron: *shirt ‚Üî t-shirt ‚Üî coat.*

![fashion_acc](../assets/qw4.png)

üß† *Insight:*  
Este dataset muestra los l√≠mites de un MLP plano y sugiere la necesidad de **redes convolucionales (CNN)** para captar patrones espaciales m√°s complejos.

---

## üñºÔ∏è Resultados: CIFAR-100 ‚Äî Im√°genes Naturales a Color

![cifar_samples](../assets/qw5.png)

```text
CIFAR-100 ‚Äî Entrenamiento
loss: 3.7601 - accuracy: 0.1682 - val_accuracy: 0.1525
```

‚úÖ **Accuracy final:** 15.2%  
‚ùå **P√©rdida final:** 3.9  

### üîç Interpretaci√≥n

- Este dataset desaf√≠a por completo al MLP: im√°genes color, ruido, y 100 categor√≠as diferentes.  
- El modelo **no logra generalizar**, debido a la p√©rdida de estructura espacial durante el aplanado.  
- Las curvas de entrenamiento oscilan mucho, lo que refleja un aprendizaje inestable.

![cifar_acc](../assets/qw6.png)

üß† *Insight:*  
El MLP no fue dise√±ado para procesar p√≠xeles RGB en estructuras 2D ‚Äî aqu√≠ **una CNN ser√≠a indispensable**.

---

## üìà Comparativa de Rendimiento Global

| Dataset | Accuracy | P√©rdida | Complejidad visual | Interpretaci√≥n |
|----------|-----------|----------|--------------------|----------------|
| **MNIST** | 0.976 | 0.081 | üü¢ Baja | Perfecto para MLP plano |
| **Fashion-MNIST** | 0.880 | 0.310 | üü° Media | Requiere capas m√°s profundas o CNN |
| **CIFAR-100** | 0.152 | 3.900 | üî¥ Alta | Demasiado complejo para un MLP puro |

![accuracy_comparison](../assets/qw7.png)

---

## üß† An√°lisis y Discusi√≥n

### üß© MLP vs Complejidad de Datos
El rendimiento decae a medida que el dataset **gana complejidad visual o dimensional**.  
Esto muestra que el MLP tiene una capacidad limitada para ‚Äúrecordar‚Äù relaciones espaciales entre p√≠xeles.

### üéõÔ∏è Impacto del Dropout
La inclusi√≥n de una capa `Dropout(0.3)` ayud√≥ a estabilizar el entrenamiento, reduciendo el sobreajuste en MNIST y Fashion-MNIST.

### ‚ö° Convergencia
- MNIST: converge r√°pido, estable desde la √©poca 4.  
- Fashion-MNIST: requiere m√°s √©pocas, pero llega a buena precisi√≥n.  
- CIFAR-100: no converge, muestra aprendizaje err√°tico.

---

## üí¨ Conclusiones Finales

1. El **MLP sigue siendo una herramienta v√°lida** para datos tabulares o im√°genes simples.  
2. La **complejidad del dataset define la arquitectura necesaria**: mientras m√°s estructura espacial, m√°s conviene usar CNN.  
3. El **Dropout y la normalizaci√≥n** demostraron ser esenciales para evitar el sobreajuste.  
4. La experiencia evidenci√≥ la importancia de experimentar: un mismo modelo **se comporta de forma muy distinta** dependiendo del dominio.  
5. El pr√≥ximo paso natural ser√° aplicar **redes convolucionales** sobre estos mismos datasets para comparar resultados.

---

## ü§î Reflexi√≥n Personal

> ‚ÄúM√°s all√° del c√≥digo, lo valioso fue entender por qu√© el modelo deja de aprender.  
> Esa observaci√≥n me llev√≥ a pensar no solo en entrenar, sino en dise√±ar arquitecturas seg√∫n la naturaleza de los datos.‚Äù

- Entend√≠ mejor la diferencia entre **capas densas** y **convolucionales**.  
- Aprend√≠ a diagnosticar cu√°ndo un modelo **es demasiado simple** para un conjunto complejo.  
- Este experimento reafirm√≥ la importancia de **la visualizaci√≥n y an√°lisis narrativo** para comunicar hallazgos de IA.

---

## üìö Evidencias

Guarda las siguientes im√°genes en tu carpeta `docs/assets/practica8-extra/`:

```
mnist_samples.png  
mnist_accuracy.png  
fashion_samples.png  
fashion_accuracy.png  
cifar_samples.png  
cifar_accuracy.png  
accuracy_comparison.png  
```

---

## üßæ Datos T√©cnicos

- **Notebook:** `Practica8_Extra_Datasets.ipynb`  
- **Lenguaje:** Python 3.10 + TensorFlow/Keras  
- **Duraci√≥n del entrenamiento:** ~12 minutos por dataset (GPU Colab)  
- **Autor:** Keyvi Alexander Garc√≠a Linares  
- **Curso:** Machine Learning ‚Äî UT2: Deep Learning Foundations  
- **Tipo de entrega:** Trabajo Extra (Ampliaci√≥n de Pr√°ctica 8)

---

üìÅ **Evidencias**  


- [![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/13zzS_ieWuIDoso6tiLAObojIBlZGWZ35?usp=sharingg) ‚Äî Notebook completo en Google Colab.