---
title: "Pr√°ctica 2: Feature Engineering simple + Modelo base"
date: 2025-01-01
---

# ‚öôÔ∏è Pr√°ctica 2 ¬∑ Feature Engineering simple + Modelo base

<div class="grid cards" markdown>

-   :material-database-cog: **Dataset**
    ---
    Titanic (Kaggle) con variables demogr√°ficas y socioecon√≥micas.

-   :material-notebook: **Notebook**
    ---
    [Abrir en Colab](https://colab.research.google.com/drive/1ut5NvjzklgNwS8wfOD07xslXUY7flhu4?usp=sharing#scrollTo=feature-engineering)

-   :material-account-badge: **Rol**
    ---
    Dise√±o de features y comparaci√≥n de modelos base (DummyClassifier vs LogisticRegression).

-   :material-flag-checkered: **Estado**
    ---
    ‚úÖ Entregado

</div>

## En una mirada

- Se consolid√≥ un pipeline reproducible que prepara datos, crea nuevas variables y entrena modelos comparables.
- La Regresi√≥n Log√≠stica alcanz√≥ un accuracy del **81.5 %**, superando ampliamente al baseline de clase mayoritaria (61 %).
- La matriz de confusi√≥n permiti√≥ priorizar mejoras enfocadas en reducir falsos negativos.

!!! tip "M√©trica a seguir"
    En futuras iteraciones, optimizar **recall** para disminuir falsos negativos en la clase positiva (sobrevivientes).

## üéØ Objetivos

- Practicar la creaci√≥n de nuevas variables (*features*) a partir de los datos originales.
- Construir un modelo base de clasificaci√≥n con **Logistic Regression** y compararlo con un modelo trivial.
- Evaluar m√©tricas de rendimiento m√°s all√° de la accuracy (precision, recall, F1, matriz de confusi√≥n).

## üóìÔ∏è Agenda express

| Actividad | Prop√≥sito | Tiempo |
|-----------|-----------|:------:|
| Revisi√≥n del dataset y limpieza | Analizar valores faltantes y preparar columnas. | 20 min |
| Creaci√≥n de nuevas features | Generar `FamilySize`, `IsAlone`, `Title` y codificar categor√≠as. | 30 min |
| Entrenamiento del modelo base | Ajustar LogisticRegression con hiperpar√°metros controlados. | 25 min |
| Evaluaci√≥n de m√©tricas | Comparar resultados con DummyClassifier y extraer aprendizajes. | 20 min |

## üîç Insights destacados

- El baseline con `DummyClassifier` fija el piso en **61 %** de accuracy.
- Las variables creadas (`FamilySize`, `IsAlone`, `Title`) aportan se√±al y elevan el desempe√±o al 81.5 %.
- La matriz de confusi√≥n revela **21 falsos negativos** ‚Üí foco para siguientes iteraciones.

## üõ†Ô∏è Desarrollo guiado

### 1. Contexto del algoritmo

#### LogisticRegression

- **¬øQu√© problemas resuelve?** Clasificaci√≥n binaria y multiclase.
- **Par√°metros relevantes:** `penalty`, `solver`, `max_iter`.
- **¬øCu√°ndo usar `solver='liblinear'`?** Adecuado para datasets peque√±os/medianos y para penalizaci√≥n L1; otros solvers (`lbfgs`, `newton-cg`) s√≥lo soportan L2 o ninguna.

#### train_test_split

- `stratify` preserva la proporci√≥n de clases en train/test.
- `random_state` asegura reproducibilidad.
- Proporci√≥n recomendada: **70/30** u **80/20** seg√∫n tama√±o de muestra.

### 2. Configuraci√≥n de entorno y datos

```python
from pathlib import Path
try:
    from google.colab import drive
    drive.mount('/content/drive')
    ROOT = Path('/content/drive/MyDrive/IA-UT1')
except Exception:
    ROOT = Path.cwd() / 'IA-UT1'

DATA_DIR = ROOT / 'data'
RESULTS_DIR = ROOT / 'results'
for d in (DATA_DIR, RESULTS_DIR):
    d.mkdir(parents=True, exist_ok=True)
print('Outputs ‚Üí', ROOT)
```

```text
Mounted at /content/drive
Outputs ‚Üí /content/drive/MyDrive/IA-UT1
```

```python
!pip -q install kaggle
from google.colab import files
files.upload()  # Sub√≠ tu archivo kaggle.json descargado
!mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json
!kaggle competitions download -c titanic -p data
!unzip -o data/titanic.zip -d data

train = pd.read_csv('data/train.csv')
test = pd.read_csv('data/test.csv')
```

```text
Se eligi√≥ un archivo
Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable.
Saving kaggle.json to kaggle.json
Downloading titanic.zip to data
  0% 0.00/34.1k [00:00<?, ?B/s]
100% 34.1k/34.1k [00:00<00:00, 165MB/s]
Archive:  data/titanic.zip
  inflating: data/gender_submission.csv
  inflating: data/test.csv
  inflating: data/train.csv
```

### 3. Feature engineering paso a paso

```python
df = train.copy()

# PASO 1 ¬∑ Imputaci√≥n
df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])
df['Fare'] = df['Fare'].fillna(df['Fare'].median())
df['Age'] = df['Age'].fillna(df.groupby(['Sex', 'Pclass'])['Age'].transform('median'))

# PASO 2 ¬∑ Nuevas variables
df['FamilySize'] = df['SibSp'] + df['Parch'] + 1
df['IsAlone'] = (df['FamilySize'] == 1).astype(int)

df['Title'] = df['Name'].str.extract(',\s*([^\.]+)\.')
rare_titles = df['Title'].value_counts()[df['Title'].value_counts() < 10].index
df['Title'] = df['Title'].replace(rare_titles, 'Rare')

# PASO 3 ¬∑ Preparaci√≥n para el modelo
features = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'FamilySize', 'IsAlone', 'Title', 'SibSp', 'Parch']
X = pd.get_dummies(df[features], drop_first=True)
y = df['Survived']

X.shape, y.shape
```

```text
((891, 14), (891,))
```

!!! note "Interpretaci√≥n"
    - Se mantienen las 891 observaciones originales.
    - Tras la codificaci√≥n, se generan **14 variables predictoras** listas para modelar.

### 4. Entrenamiento y evaluaci√≥n

```python
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.dummy import DummyClassifier

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

dummy = DummyClassifier(strategy='most_frequent', random_state=42)
dummy.fit(X_train, y_train)

log_reg = LogisticRegression(max_iter=1000, solver='liblinear')
log_reg.fit(X_train, y_train)

baseline_acc = accuracy_score(y_test, dummy.predict(X_test))
model_acc = accuracy_score(y_test, log_reg.predict(X_test))
```

```python
print(f"Baseline accuracy: {baseline_acc:.3f}")
print(f"Logistic Regression accuracy: {model_acc:.3f}")
print(classification_report(y_test, log_reg.predict(X_test)))
print(confusion_matrix(y_test, log_reg.predict(X_test)))
```

!!! success "Resultados"
    - **Baseline:** 0.611
    - **Logistic Regression:** 0.815
    - 21 falsos negativos identificados en la matriz de confusi√≥n.

## ‚úÖ Cierre y pr√≥ximos pasos

- Documentaci√≥n del pipeline lista para iterar con validaci√≥n cruzada.
- Prioridad: explorar regularizaci√≥n y ajuste de umbral para mejorar recall.
- Integrar visualizaciones de importancia de features para presentar a stakeholders.
